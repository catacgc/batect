{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Introduction \u00b6 What is batect? \u00b6 batect allows you to define your development tasks (building, running, testing, linting and more) in terms of one or more Docker containers, run those tasks quickly and consistently everywhere, and easily share them with your team. batect is: fast : Tasks start quickly due to parallelisation, run quickly thanks to caching, and clean up reliably every time - we've seen 17% quicker execution than Docker Compose. easy to use : Easily share your development tasks with your whole team, and free them from manual setup of build tools and dependencies for tasks like running your app locally or integration testing. And no installation is required either - just drop the script in your project and batect takes care of the rest. consistent : batect uses Docker to create a clean, isolated environment every time you run a task, freeing you from \"works on my machine\" issues - including on CI. versatile : Anything that can run in a Docker container can be run with batect - builds, unit testing, integration testing, linting, local environments, deployments; frontend, backend or somewhere in between, batect can do it all. What is batect not? \u00b6 a build tool - instead, use your chosen language's existing tooling (eg. Gradle, Rake, CMake or Cargo) from within a batect task a deployment tool - instead, use your target environment's existing tooling (eg. kubectl) from within a batect task a CI tool - instead, use your existing CI tool and have it run batect What are batect's system requirements? \u00b6 batect requires Docker 18.03.1 or newer, Java 8 or newer (although this requirement will be removed before v1.0), and: On Linux and macOS: Bash and curl On Windows: Windows 10 / Windows Server 2016 or later batect supports both Linux and Windows containers. A 64-bit version of Java is required on Windows. I'm sold! How do I get started? \u00b6 Take a look at the setup instructions . What's going on under the hood? \u00b6 Take a look at the task lifecycle to understand how batect executes tasks. Why would I use batect? \u00b6 Every application has a build environment - the tools and configuration needed to take the source code and produce an artifact ready for use. However, setting this up can be time consuming and frustrating. Too often new team members' first experience on a project is a few days working out which tools they need to install, and another few days of then discovering the magic combination of tool versions that will happily coexist. And as the application evolves and changes over time, maintaining and updating this environment across all developers' machines and CI agents can be incredibly painful. Similarly, most applications have external dependencies - for example, other services, databases, caches, credential storage systems... the list is endless. Because of this, we would like to run integration, component or journey tests where the application itself (or some part of it) interacts with these external dependencies. In some cases, we'd like to use a real instance of it (eg. a running Postgres instance), and in other cases, we'd like to use a fake (eg. a fake implementation of a downstream service). Either way, installing, configuring and managing all these dependencies takes a lot of work, and making sure they're in a known state before a test run is key to reducing test flakiness. Add in networking gremlins, different operating systems, personal preferences, built-up cruft and manual configuration and you end up with an enormous number of variables that lead to a huge amount of wasted time spent debugging issues that are entirely preventable. batect helps solve these problems by: allowing you to entirely automate the setup of your build and testing environments storing this automation alongside your application code, so that it is versioned and updated just like any other part of your application ensuring that every single command invocation starts with a completely fresh environment based on your configuration file, making it impossible to get out-of-sync from the desired state providing an easy mechanism for developers to discover what tasks are available: ./batect --list-tasks making use of Docker to do all of this in an isolated and low-overhead way using some smart dependency management logic, parallelism and Docker's caching features to do all of this very, very quickly taking advantage of Docker's networking features to set up an isolated network for every command enabling you to use existing Docker images as-is (or easily use custom Dockerfiles) to quickly get up and running Where does the name come from? \u00b6 b uild a nd t esting e nvironments as c ode t ool","title":"Introduction"},{"location":"index.html#introduction","text":"","title":"Introduction"},{"location":"index.html#what-is-batect","text":"batect allows you to define your development tasks (building, running, testing, linting and more) in terms of one or more Docker containers, run those tasks quickly and consistently everywhere, and easily share them with your team. batect is: fast : Tasks start quickly due to parallelisation, run quickly thanks to caching, and clean up reliably every time - we've seen 17% quicker execution than Docker Compose. easy to use : Easily share your development tasks with your whole team, and free them from manual setup of build tools and dependencies for tasks like running your app locally or integration testing. And no installation is required either - just drop the script in your project and batect takes care of the rest. consistent : batect uses Docker to create a clean, isolated environment every time you run a task, freeing you from \"works on my machine\" issues - including on CI. versatile : Anything that can run in a Docker container can be run with batect - builds, unit testing, integration testing, linting, local environments, deployments; frontend, backend or somewhere in between, batect can do it all.","title":"What is batect?"},{"location":"index.html#what-is-batect-not","text":"a build tool - instead, use your chosen language's existing tooling (eg. Gradle, Rake, CMake or Cargo) from within a batect task a deployment tool - instead, use your target environment's existing tooling (eg. kubectl) from within a batect task a CI tool - instead, use your existing CI tool and have it run batect","title":"What is batect not?"},{"location":"index.html#what-are-batects-system-requirements","text":"batect requires Docker 18.03.1 or newer, Java 8 or newer (although this requirement will be removed before v1.0), and: On Linux and macOS: Bash and curl On Windows: Windows 10 / Windows Server 2016 or later batect supports both Linux and Windows containers. A 64-bit version of Java is required on Windows.","title":"What are batect's system requirements?"},{"location":"index.html#im-sold-how-do-i-get-started","text":"Take a look at the setup instructions .","title":"I'm sold! How do I get started?"},{"location":"index.html#whats-going-on-under-the-hood","text":"Take a look at the task lifecycle to understand how batect executes tasks.","title":"What's going on under the hood?"},{"location":"index.html#why-would-i-use-batect","text":"Every application has a build environment - the tools and configuration needed to take the source code and produce an artifact ready for use. However, setting this up can be time consuming and frustrating. Too often new team members' first experience on a project is a few days working out which tools they need to install, and another few days of then discovering the magic combination of tool versions that will happily coexist. And as the application evolves and changes over time, maintaining and updating this environment across all developers' machines and CI agents can be incredibly painful. Similarly, most applications have external dependencies - for example, other services, databases, caches, credential storage systems... the list is endless. Because of this, we would like to run integration, component or journey tests where the application itself (or some part of it) interacts with these external dependencies. In some cases, we'd like to use a real instance of it (eg. a running Postgres instance), and in other cases, we'd like to use a fake (eg. a fake implementation of a downstream service). Either way, installing, configuring and managing all these dependencies takes a lot of work, and making sure they're in a known state before a test run is key to reducing test flakiness. Add in networking gremlins, different operating systems, personal preferences, built-up cruft and manual configuration and you end up with an enormous number of variables that lead to a huge amount of wasted time spent debugging issues that are entirely preventable. batect helps solve these problems by: allowing you to entirely automate the setup of your build and testing environments storing this automation alongside your application code, so that it is versioned and updated just like any other part of your application ensuring that every single command invocation starts with a completely fresh environment based on your configuration file, making it impossible to get out-of-sync from the desired state providing an easy mechanism for developers to discover what tasks are available: ./batect --list-tasks making use of Docker to do all of this in an isolated and low-overhead way using some smart dependency management logic, parallelism and Docker's caching features to do all of this very, very quickly taking advantage of Docker's networking features to set up an isolated network for every command enabling you to use existing Docker images as-is (or easily use custom Dockerfiles) to quickly get up and running","title":"Why would I use batect?"},{"location":"index.html#where-does-the-name-come-from","text":"b uild a nd t esting e nvironments as c ode t ool","title":"Where does the name come from?"},{"location":"CLIReference.html","text":"CLI reference \u00b6 Note This page reflects the options available in the most recent version of batect. If you are not running the most recent version, run ./batect --help to see what options are available in your version. Run a task \u00b6 Run a task by running ./batect <task-name> . For example, to run the-task , run ./batect the-task . You can also pass arguments to the task command by passing those arguments by running ./batect <task-name> -- <args...> . For example, to run the task the-task with the arguments arg1 arg2 , run ./batect the-task -- arg1 arg2 . Set config variables from a file ( --config-vars-file ) \u00b6 By default, batect will automatically apply values for config variables from the YAML file batect.local.yml if it exists. Use --config-vars-file to specify a different file to use. Values provided with --config-var take precedence over values provided in any file. Example: ./batect --config-vars-file batect.ci.yml the-task Example batect.ci.yml contents: log_level : debug user_name : alex Set a config variable ( --config-var ) \u00b6 Use --config-vars to specify values for an individual config variable . Values must be in the format <variable name>=<variable value> . Values provided with --config-var take precedence over values provided in a file (either explicitly with --config-vars-file or from the default batect.local.yml file) and default values defined in the configuration file. Example: ./batect --config-var log_level = debug the-task Override the image used by a container ( --override-image ) \u00b6 By default, batect will use the image defined in the configuration file (either with image or build_directory ). Use this option to override the value in the configuration file and use a different image for a specific container. Values must be in the format <container name>=<image> . Example: ./batect --override-image build-env = ruby:2.7.0 the-task Disable cleaning up ( --no-cleanup , --no-cleanup-after-failure and --no-cleanup-after-success ) \u00b6 By default, batect will automatically cleanup all containers and other resources it creates while running a task. However, sometimes it can be useful to leave all the created containers running to diagnose issues running a task. Use --no-cleanup-after-failure to not clean up if any task fails to start for any reason. Use --no-cleanup-after-success to not clean up the containers and other resources created for the main task (the one specified on the command line) if it succeeds. Use --no-cleanup to enable both of the above. Example: ./batect --no-cleanup-after-failure the-task Disable propagation of proxy-related environment variables ( --no-proxy-vars ) \u00b6 By default, batect will automatically propagate proxy-related environment variables as described here . Use this option to disable this behaviour. Example: ./batect --no-proxy-vars the-task Use an existing network for tasks ( --use-network ) \u00b6 By default, batect will create a new Docker network for each task, as described in the task lifecycle . Use this option to provide an existing network to use for all tasks. Example: ./batect --use-network = my-existing-network the-task See a list of available tasks ( --list-tasks or -T ) \u00b6 batect can produce a short summary of all tasks in the current configuration file along with their description , and grouped by their group . For example, ./batect --list-tasks produces output like this: Build tasks: - build: Build the application. Test tasks: - continuousUnitTest: Run the unit tests in watch mode. - unitTest: Run the unit tests once. Utility tasks: - outdated: Check for outdated dependencies. - shell: Start a shell in the development environment. Cleanup all caches for this project ( --clean ) \u00b6 Running ./batect --clean will remove all caches created for this project. This command respects the value of the --cache-type option and the BATECT_CACHE_TYPE environment variable. Upgrade batect ( --upgrade ) \u00b6 Running ./batect --upgrade will automatically upgrade batect in the current project to the latest available version. Get help for batect's CLI ( --help ) \u00b6 Running ./batect --help will show a summary of the options available on the command line. Get batect, Docker and OS version information ( --version ) \u00b6 Running ./batect --version will show a summary of the versions of batect, Docker and your operating system, which can be useful when diagnosing issues with batect. Common options \u00b6 Use a non-standard configuration file name ( --config-file or -f ) \u00b6 By default, batect will use a configuration file called batect.yml in the current directory. Use this option to instruct batect to use a different file. Example: ./batect --config-file my-other-config-file.yml the-task Customise cache storage mechanism ( --cache-type ) \u00b6 By default, batect will use a Docker volume for each cache mount for Linux containers. Use this option to instruct batect to use a different storage mechanism. Supported values are: volume : use Docker volumes directory : use directories mounted from the project's .batect/caches directory The BATECT_CACHE_TYPE environment variable can also be used to set the default cache type. If both the environment variable and the --cache-type option are set, the value given with --cache-type takes precedence. Info This option has no effect on Windows containers. Windows containers always use directory mounts for caches. Example: ./batect --cache-type = directory the-task Set cache initialisation image ( --linux-cache-init-image ) \u00b6 batect uses an image to initialise cache volumes before they are mounted. Use this option to override the default image. This is useful if you have cached the initialisation image on a local registry. The BATECT_LINUX_CACHE_INIT_IMAGE environment variable can also be used to set the default initialisation image. If both the environment variable and the --linux-cache-init-image option are set, the value given with --linux-cache-init-image takes precedence. Example: ./batect --linux-cache-init-image = my.registry.com/batect-cache-init-image:abcd1234 the-task Customise Docker connection options \u00b6 Use a non-standard Docker host ( --docker-host ) \u00b6 By default, batect will connect to the Docker daemon using the path provided in the DOCKER_HOST environment variable, or the default path for your operating system if DOCKER_HOST is not set. Use this option to instruct batect to use a different path. Example: ./batect --docker-host unix:///var/run/other-docker.sock the-task Connect to Docker over TLS ( --docker-tls and --docker-tls-verify ) \u00b6 By default, the Docker daemon only accepts plaintext connections from the local machine. If your daemon requires TLS, use the --docker-tls-verify option to instruct batect to use TLS. batect will also automatically enable this option if the DOCKER_TLS_VERIFY environment variable is set to 1 . If your daemon presents a certificate that does not match its hostname, use the --docker-tls option (without --docker-tls-verify ) to instruct batect to not verify the hostname. Warning Using --docker-tls without --docker-tls-verify is insecure and should only be used if you understand the implications of this. These options mirror the behaviour of the docker CLI's --tls and --tlsverify options. Customise certificates used to provide authentication to daemon and to verify daemon's identity ( --docker-cert-path , --docker-tls-ca-cert , --docker-tls-cert and --docker-tls-key ) \u00b6 If your Docker daemon requires TLS, batect needs three files in order to connect to it: the CA certificate that can be used to verify certificates presented by the Docker daemon ( --docker-tls-ca-cert ) the certificate that can be used to prove your identity to the Docker daemon ( --docker-tls-cert ) and corresponding private key ( --docker-tls-key ) By default, these files are stored in ~/.docker and are named ca.pem , cert.pem and key.pem respectively. You can instruct batect use a non-default location for any of these files with the options mentioned above, or override the default directory for these files with --docker-cert-path . If the DOCKER_CERT_PATH environment variable is set, batect will use that as the default directory. If both --docker-cert-path (or DOCKER_CERT_PATH ) and a path for an individual file is provided, the path for the individual file takes precedence. These options mirror the behaviour of the docker CLI's --tlscacert , --tlscert and --tlskey options. Create a debugging log ( --log-file ) \u00b6 Use this option to instruct batect to generate a debugging log at the specified path as it runs. This may be requested if you submit an issue. If the log file already exists, batect will append further log messages to the end of the file. Example: ./batect --log-file /tmp/debugging-log.json the-task Disable coloured output ( --no-color ) \u00b6 By default, batect will produce coloured output if it detects that your console supports it. However, sometimes batect may incorrectly believe your console supports coloured output, or your console may incorrectly report that it supports coloured output when it does not. (This is a common issue with some CI systems.) This can lead to garbled or difficult to read output. Passing this flag will disable all coloured output, even if batect believes your console supports it. Example: ./batect --no-color the-task Disable update notification ( --no-update-notification ) \u00b6 batect automatically checks for updates at most once every 24 hours and displays a notification if a newer version is available. Passing this flag will disable both the update check and notification. This flag is automatically enabled if --output is set to quiet . Disable wrapper cache cleanup ( --no-wrapper-cache-cleanup ) \u00b6 batect automatically removes old versions of itself that have been downloaded and cached locally if they haven't been used in 30 days. Passing this flag will disable this cleanup process. You can manually remove these files from ~/.batect/cache yourself at any time. Force a particular output style ( --output or -o ) \u00b6 batect offers four styles of output: fancy is best for interactive use, providing very clean output about the current state of execution and showing output from only the task container simple is best for non-interactive use (eg. on CI), providing a log of what happened and showing output from only the task container all displays output from all containers quiet displays only the output from the task and error messages from batect There are some differences between these output styles to be aware of: Output style fancy simple quiet all Progress information Detailed (eg. download % completed, health check status) Basic (eg. image pull started, container ready) Errors only Basic (eg. image pull started, container ready) Displays output from Task container only Task container only Task container only All containers stdin connected (if present) Yes, to task container only Yes, to task container only Yes, to task container only No TTY connected (if present) Yes, to task container only Yes, to task container only Yes, to task container only No Image build output shown Only on build failure Only on build failure Only on build failure Always By default, batect will automatically pick an output style that it believes is appropriate for the environment it is running in - fancy if it believes your environment supports it, or simple otherwise. Passing this flag allows you to override what batect believes is appropriate. Example: ./batect --output simple the-task Passing --output=quiet implies --no-update-notification . General notes \u00b6 All command line options that take a value can be provided in --option=value or --option value format.","title":"CLI reference"},{"location":"CLIReference.html#cli-reference","text":"Note This page reflects the options available in the most recent version of batect. If you are not running the most recent version, run ./batect --help to see what options are available in your version.","title":"CLI reference"},{"location":"CLIReference.html#run-a-task","text":"Run a task by running ./batect <task-name> . For example, to run the-task , run ./batect the-task . You can also pass arguments to the task command by passing those arguments by running ./batect <task-name> -- <args...> . For example, to run the task the-task with the arguments arg1 arg2 , run ./batect the-task -- arg1 arg2 .","title":"Run a task"},{"location":"CLIReference.html#set-config-variables-from-a-file-config-vars-file","text":"By default, batect will automatically apply values for config variables from the YAML file batect.local.yml if it exists. Use --config-vars-file to specify a different file to use. Values provided with --config-var take precedence over values provided in any file. Example: ./batect --config-vars-file batect.ci.yml the-task Example batect.ci.yml contents: log_level : debug user_name : alex","title":"Set config variables from a file (--config-vars-file)"},{"location":"CLIReference.html#set-a-config-variable-config-var","text":"Use --config-vars to specify values for an individual config variable . Values must be in the format <variable name>=<variable value> . Values provided with --config-var take precedence over values provided in a file (either explicitly with --config-vars-file or from the default batect.local.yml file) and default values defined in the configuration file. Example: ./batect --config-var log_level = debug the-task","title":"Set a config variable (--config-var)"},{"location":"CLIReference.html#override-the-image-used-by-a-container-override-image","text":"By default, batect will use the image defined in the configuration file (either with image or build_directory ). Use this option to override the value in the configuration file and use a different image for a specific container. Values must be in the format <container name>=<image> . Example: ./batect --override-image build-env = ruby:2.7.0 the-task","title":"Override the image used by a container (--override-image)"},{"location":"CLIReference.html#disable-cleaning-up-no-cleanup-no-cleanup-after-failure-and-no-cleanup-after-success","text":"By default, batect will automatically cleanup all containers and other resources it creates while running a task. However, sometimes it can be useful to leave all the created containers running to diagnose issues running a task. Use --no-cleanup-after-failure to not clean up if any task fails to start for any reason. Use --no-cleanup-after-success to not clean up the containers and other resources created for the main task (the one specified on the command line) if it succeeds. Use --no-cleanup to enable both of the above. Example: ./batect --no-cleanup-after-failure the-task","title":"Disable cleaning up (--no-cleanup, --no-cleanup-after-failure and --no-cleanup-after-success)"},{"location":"CLIReference.html#disable-propagation-of-proxy-related-environment-variables-no-proxy-vars","text":"By default, batect will automatically propagate proxy-related environment variables as described here . Use this option to disable this behaviour. Example: ./batect --no-proxy-vars the-task","title":"Disable propagation of proxy-related environment variables (--no-proxy-vars)"},{"location":"CLIReference.html#use-an-existing-network-for-tasks-use-network","text":"By default, batect will create a new Docker network for each task, as described in the task lifecycle . Use this option to provide an existing network to use for all tasks. Example: ./batect --use-network = my-existing-network the-task","title":"Use an existing network for tasks (--use-network)"},{"location":"CLIReference.html#see-a-list-of-available-tasks-list-tasks-or-t","text":"batect can produce a short summary of all tasks in the current configuration file along with their description , and grouped by their group . For example, ./batect --list-tasks produces output like this: Build tasks: - build: Build the application. Test tasks: - continuousUnitTest: Run the unit tests in watch mode. - unitTest: Run the unit tests once. Utility tasks: - outdated: Check for outdated dependencies. - shell: Start a shell in the development environment.","title":"See a list of available tasks (--list-tasks or -T)"},{"location":"CLIReference.html#cleanup-all-caches-for-this-project-clean","text":"Running ./batect --clean will remove all caches created for this project. This command respects the value of the --cache-type option and the BATECT_CACHE_TYPE environment variable.","title":"Cleanup all caches for this project (--clean)"},{"location":"CLIReference.html#upgrade-batect-upgrade","text":"Running ./batect --upgrade will automatically upgrade batect in the current project to the latest available version.","title":"Upgrade batect (--upgrade)"},{"location":"CLIReference.html#get-help-for-batects-cli-help","text":"Running ./batect --help will show a summary of the options available on the command line.","title":"Get help for batect's CLI (--help)"},{"location":"CLIReference.html#get-batect-docker-and-os-version-information-version","text":"Running ./batect --version will show a summary of the versions of batect, Docker and your operating system, which can be useful when diagnosing issues with batect.","title":"Get batect, Docker and OS version information (--version)"},{"location":"CLIReference.html#common-options","text":"","title":"Common options"},{"location":"CLIReference.html#use-a-non-standard-configuration-file-name-config-file-or-f","text":"By default, batect will use a configuration file called batect.yml in the current directory. Use this option to instruct batect to use a different file. Example: ./batect --config-file my-other-config-file.yml the-task","title":"Use a non-standard configuration file name (--config-file or -f)"},{"location":"CLIReference.html#customise-cache-storage-mechanism-cache-type","text":"By default, batect will use a Docker volume for each cache mount for Linux containers. Use this option to instruct batect to use a different storage mechanism. Supported values are: volume : use Docker volumes directory : use directories mounted from the project's .batect/caches directory The BATECT_CACHE_TYPE environment variable can also be used to set the default cache type. If both the environment variable and the --cache-type option are set, the value given with --cache-type takes precedence. Info This option has no effect on Windows containers. Windows containers always use directory mounts for caches. Example: ./batect --cache-type = directory the-task","title":"Customise cache storage mechanism (--cache-type)"},{"location":"CLIReference.html#set-cache-initialisation-image-linux-cache-init-image","text":"batect uses an image to initialise cache volumes before they are mounted. Use this option to override the default image. This is useful if you have cached the initialisation image on a local registry. The BATECT_LINUX_CACHE_INIT_IMAGE environment variable can also be used to set the default initialisation image. If both the environment variable and the --linux-cache-init-image option are set, the value given with --linux-cache-init-image takes precedence. Example: ./batect --linux-cache-init-image = my.registry.com/batect-cache-init-image:abcd1234 the-task","title":"Set cache initialisation image (--linux-cache-init-image)"},{"location":"CLIReference.html#customise-docker-connection-options","text":"","title":"Customise Docker connection options"},{"location":"CLIReference.html#use-a-non-standard-docker-host-docker-host","text":"By default, batect will connect to the Docker daemon using the path provided in the DOCKER_HOST environment variable, or the default path for your operating system if DOCKER_HOST is not set. Use this option to instruct batect to use a different path. Example: ./batect --docker-host unix:///var/run/other-docker.sock the-task","title":"Use a non-standard Docker host (--docker-host)"},{"location":"CLIReference.html#connect-to-docker-over-tls-docker-tls-and-docker-tls-verify","text":"By default, the Docker daemon only accepts plaintext connections from the local machine. If your daemon requires TLS, use the --docker-tls-verify option to instruct batect to use TLS. batect will also automatically enable this option if the DOCKER_TLS_VERIFY environment variable is set to 1 . If your daemon presents a certificate that does not match its hostname, use the --docker-tls option (without --docker-tls-verify ) to instruct batect to not verify the hostname. Warning Using --docker-tls without --docker-tls-verify is insecure and should only be used if you understand the implications of this. These options mirror the behaviour of the docker CLI's --tls and --tlsverify options.","title":"Connect to Docker over TLS (--docker-tls and --docker-tls-verify)"},{"location":"CLIReference.html#customise-certificates-used-to-provide-authentication-to-daemon-and-to-verify-daemons-identity-docker-cert-path-docker-tls-ca-cert-docker-tls-cert-and-docker-tls-key","text":"If your Docker daemon requires TLS, batect needs three files in order to connect to it: the CA certificate that can be used to verify certificates presented by the Docker daemon ( --docker-tls-ca-cert ) the certificate that can be used to prove your identity to the Docker daemon ( --docker-tls-cert ) and corresponding private key ( --docker-tls-key ) By default, these files are stored in ~/.docker and are named ca.pem , cert.pem and key.pem respectively. You can instruct batect use a non-default location for any of these files with the options mentioned above, or override the default directory for these files with --docker-cert-path . If the DOCKER_CERT_PATH environment variable is set, batect will use that as the default directory. If both --docker-cert-path (or DOCKER_CERT_PATH ) and a path for an individual file is provided, the path for the individual file takes precedence. These options mirror the behaviour of the docker CLI's --tlscacert , --tlscert and --tlskey options.","title":"Customise certificates used to provide authentication to daemon and to verify daemon's identity (--docker-cert-path, --docker-tls-ca-cert, --docker-tls-cert and --docker-tls-key)"},{"location":"CLIReference.html#create-a-debugging-log-log-file","text":"Use this option to instruct batect to generate a debugging log at the specified path as it runs. This may be requested if you submit an issue. If the log file already exists, batect will append further log messages to the end of the file. Example: ./batect --log-file /tmp/debugging-log.json the-task","title":"Create a debugging log (--log-file)"},{"location":"CLIReference.html#disable-coloured-output-no-color","text":"By default, batect will produce coloured output if it detects that your console supports it. However, sometimes batect may incorrectly believe your console supports coloured output, or your console may incorrectly report that it supports coloured output when it does not. (This is a common issue with some CI systems.) This can lead to garbled or difficult to read output. Passing this flag will disable all coloured output, even if batect believes your console supports it. Example: ./batect --no-color the-task","title":"Disable coloured output (--no-color)"},{"location":"CLIReference.html#disable-update-notification-no-update-notification","text":"batect automatically checks for updates at most once every 24 hours and displays a notification if a newer version is available. Passing this flag will disable both the update check and notification. This flag is automatically enabled if --output is set to quiet .","title":"Disable update notification (--no-update-notification)"},{"location":"CLIReference.html#disable-wrapper-cache-cleanup-no-wrapper-cache-cleanup","text":"batect automatically removes old versions of itself that have been downloaded and cached locally if they haven't been used in 30 days. Passing this flag will disable this cleanup process. You can manually remove these files from ~/.batect/cache yourself at any time.","title":"Disable wrapper cache cleanup (--no-wrapper-cache-cleanup)"},{"location":"CLIReference.html#force-a-particular-output-style-output-or-o","text":"batect offers four styles of output: fancy is best for interactive use, providing very clean output about the current state of execution and showing output from only the task container simple is best for non-interactive use (eg. on CI), providing a log of what happened and showing output from only the task container all displays output from all containers quiet displays only the output from the task and error messages from batect There are some differences between these output styles to be aware of: Output style fancy simple quiet all Progress information Detailed (eg. download % completed, health check status) Basic (eg. image pull started, container ready) Errors only Basic (eg. image pull started, container ready) Displays output from Task container only Task container only Task container only All containers stdin connected (if present) Yes, to task container only Yes, to task container only Yes, to task container only No TTY connected (if present) Yes, to task container only Yes, to task container only Yes, to task container only No Image build output shown Only on build failure Only on build failure Only on build failure Always By default, batect will automatically pick an output style that it believes is appropriate for the environment it is running in - fancy if it believes your environment supports it, or simple otherwise. Passing this flag allows you to override what batect believes is appropriate. Example: ./batect --output simple the-task Passing --output=quiet implies --no-update-notification .","title":"Force a particular output style (--output or -o)"},{"location":"CLIReference.html#general-notes","text":"All command line options that take a value can be provided in --option=value or --option value format.","title":"General notes"},{"location":"Comparison.html","text":"Comparison with other tools \u00b6 Feedback wanted Are you wondering about how batect compares to other tools? Do you have your own reasons for or against batect compared to one of the tools mentioned below? Please file an issue with your questions, comments and feedback. How does batect compare to... ...using shell scripts to drive Docker? \u00b6 While it's certainly possible, it quickly gets unwieldy and is difficult to effectively parallelise tasks that can run in parallel. It is also difficult to ensure that all resources created during the task, such as containers and networks, are always correctly cleaned up once the task completes, especially if the task fails. ...Docker Compose? \u00b6 In the past, I've used Docker Compose to implement the same idea that is at the core of batect. However, using Docker Compose for this purpose has a number of drawbacks. In particular, Docker Compose is geared towards describing an application and its dependencies and starting this whole stack. Its CLI is designed with this purpose in mind, making it frustrating to use day-to-day as a development tool and necessitating the use of a higher-level script to automate its usage. Furthermore, Docker Compose has no concept of tasks, further cementing the need to use a higher-level script to provide the ability to execute different commands, run prerequisite tasks or setup commands and provide the discoverability that comes with a go script . Docker Compose is also significantly slower than batect, as it does not parallelise all operations - in one test, batect was 17% faster than Docker Compose. It also does not elegantly support pulling together a set of containers in different configurations (eg. integration vs functional testing), does not handle proxies or file permission issues on Linux automatically and does not support waiting for dependencies to become healthy as of version 3. ...Dojo? \u00b6 Dojo was built with very similar goals to batect, but takes a slightly different approach. There are a number of differences between Dojo and batect: Dojo requires local installation, which means different developers can be running different versions of Dojo. Batect uses a wrapper script committed to source control to manage the version of batect and ensure that everyone - developers and CI - use the same version and so have a consistent experience. Dojo requires Docker images to conform to a number of requirements to make the most of its features. Batect supports using any Docker image and instead requires some features to be configured in your batect configuration file. Dojo does not have built-in support for running multiple containers and instead delegates to Docker Compose to manage multiple containers, with many of the drawbacks described above including noticeably lower performance. Dojo does not support using a local Dockerfile. batect supports this as a first-class citizen, which allows developers to easily extend images for their needs without needing to publish them to a Docker image registry. Dojo has no concept of tasks and requires documentation such as a readme or a separate script to communicate these to developers. Batect supports tasks and prerequisites, removing the need for a separate go script . Dojo has very verbose and detailed default output. batect omits details that would largely be irrelevant in day-to-day development work by default and instead focuses on output from tasks. Dojo does not support Windows or Windows containers, whereas batect does. Dojo lacks more advanced features that batect provides to make working with Docker easier and faster, such as cache volumes and automatic configuration of proxies . ...CI tools with a local runner? \u00b6 As an example, both GitLab CI and CircleCI have CLIs that allow you to run your build on your local machine, using the same containers (and therefore environment) as they do when running your build on the CI server. These tools have been designed to primarily be great CI servers, with the local CLI intended to be a convenience to allow developers to test changes to the build configuration, rather than being a day-to-day development tool. batect, on the other hand, was designed from the beginning to be a great day-to-day development tool that also works equally well on CI. Specific drawbacks of these tools compared to using batect include: batect provides a significantly better developer experience, with a simpler, easier to use CLI, clearer and more concise output (with more details available when required), and clearer error messages. One specific example would be the experience when a dependency container fails to become healthy - batect will not only tell you which container did not become healthy, but also automatically display the output from the last health check, and also provides the option to not clean up the dependency containers if they fail to allow you to investigate further. batect supports using local Dockerfiles to define the images used, rather than requiring that all images be pushed to a Docker registry. This provides a number of benefits: Additional configuration or installation of software over and above what is included in the base image can be codified in the Dockerfile, built once per machine that uses it and then cached, saving time over doing this additional configuration or installation at the beginning of each and every build. This also reduces the need to bloat the base image with configuration or software required by only one or two users of the base image, reducing their size and improving maintainability. Enabling changes to be made to the build and testing environments in the same repository as the application's code enhances traceability and understanding of why changes were made - the code change can form part of the same commit as the environmental change required to support it. These tools have only basic support for dependencies in other containers (for example, a database used for integration testing), and require the configuration of other tools such as Dockerize to ensure that dependencies are ready for use before they are used. This does not take advantage of images' built-in health checks and the benefits this mechanism has, such as a warm-up period. Furthermore, this leaves the developer to manually manage transitive dependencies between these containers, and all of the limitations with regard to the images used for the build environment discussed above apply equally to dependency images. These tools don't provide time-saving functionality such as automatically configuring proxies at image build time and in the container . As these tools are designed to run the build and only the build in exactly the same way every time, they do not support passing additional arguments to the task, making it difficult to change options for tasks that may be helpful during development, such as enabling a debugger or more verbose logging. These tools don't support easily mounting the local working copy into the build container, which means they can't be used for tasks that rely on detecting changes to code, such as a continuous unit test task. These tools don't have a way to easily codify and share tasks not used in the build but used by developers, such as a task that spins up the app with stubbed dependencies. ...Vagrant? \u00b6 Vagrant's use of virtual machines means that it is very heavyweight, making it difficult to run multiple projects' environments at once. This is especially problematic on CI servers where we'd like to run multiple builds in parallel. Furthermore, the long-lived nature of virtual machines means that it's very easy for a developer's machine to get out of sync with the desired configuration, and nothing automatically re-provisions the machine when the configuration is changed - a developer has to remember to re-run the provisioning step if the configuration changes.","title":"Comparison with other tools"},{"location":"Comparison.html#comparison-with-other-tools","text":"Feedback wanted Are you wondering about how batect compares to other tools? Do you have your own reasons for or against batect compared to one of the tools mentioned below? Please file an issue with your questions, comments and feedback. How does batect compare to...","title":"Comparison with other tools"},{"location":"Comparison.html#using-shell-scripts-to-drive-docker","text":"While it's certainly possible, it quickly gets unwieldy and is difficult to effectively parallelise tasks that can run in parallel. It is also difficult to ensure that all resources created during the task, such as containers and networks, are always correctly cleaned up once the task completes, especially if the task fails.","title":"...using shell scripts to drive Docker?"},{"location":"Comparison.html#docker-compose","text":"In the past, I've used Docker Compose to implement the same idea that is at the core of batect. However, using Docker Compose for this purpose has a number of drawbacks. In particular, Docker Compose is geared towards describing an application and its dependencies and starting this whole stack. Its CLI is designed with this purpose in mind, making it frustrating to use day-to-day as a development tool and necessitating the use of a higher-level script to automate its usage. Furthermore, Docker Compose has no concept of tasks, further cementing the need to use a higher-level script to provide the ability to execute different commands, run prerequisite tasks or setup commands and provide the discoverability that comes with a go script . Docker Compose is also significantly slower than batect, as it does not parallelise all operations - in one test, batect was 17% faster than Docker Compose. It also does not elegantly support pulling together a set of containers in different configurations (eg. integration vs functional testing), does not handle proxies or file permission issues on Linux automatically and does not support waiting for dependencies to become healthy as of version 3.","title":"...Docker Compose?"},{"location":"Comparison.html#dojo","text":"Dojo was built with very similar goals to batect, but takes a slightly different approach. There are a number of differences between Dojo and batect: Dojo requires local installation, which means different developers can be running different versions of Dojo. Batect uses a wrapper script committed to source control to manage the version of batect and ensure that everyone - developers and CI - use the same version and so have a consistent experience. Dojo requires Docker images to conform to a number of requirements to make the most of its features. Batect supports using any Docker image and instead requires some features to be configured in your batect configuration file. Dojo does not have built-in support for running multiple containers and instead delegates to Docker Compose to manage multiple containers, with many of the drawbacks described above including noticeably lower performance. Dojo does not support using a local Dockerfile. batect supports this as a first-class citizen, which allows developers to easily extend images for their needs without needing to publish them to a Docker image registry. Dojo has no concept of tasks and requires documentation such as a readme or a separate script to communicate these to developers. Batect supports tasks and prerequisites, removing the need for a separate go script . Dojo has very verbose and detailed default output. batect omits details that would largely be irrelevant in day-to-day development work by default and instead focuses on output from tasks. Dojo does not support Windows or Windows containers, whereas batect does. Dojo lacks more advanced features that batect provides to make working with Docker easier and faster, such as cache volumes and automatic configuration of proxies .","title":"...Dojo?"},{"location":"Comparison.html#ci-tools-with-a-local-runner","text":"As an example, both GitLab CI and CircleCI have CLIs that allow you to run your build on your local machine, using the same containers (and therefore environment) as they do when running your build on the CI server. These tools have been designed to primarily be great CI servers, with the local CLI intended to be a convenience to allow developers to test changes to the build configuration, rather than being a day-to-day development tool. batect, on the other hand, was designed from the beginning to be a great day-to-day development tool that also works equally well on CI. Specific drawbacks of these tools compared to using batect include: batect provides a significantly better developer experience, with a simpler, easier to use CLI, clearer and more concise output (with more details available when required), and clearer error messages. One specific example would be the experience when a dependency container fails to become healthy - batect will not only tell you which container did not become healthy, but also automatically display the output from the last health check, and also provides the option to not clean up the dependency containers if they fail to allow you to investigate further. batect supports using local Dockerfiles to define the images used, rather than requiring that all images be pushed to a Docker registry. This provides a number of benefits: Additional configuration or installation of software over and above what is included in the base image can be codified in the Dockerfile, built once per machine that uses it and then cached, saving time over doing this additional configuration or installation at the beginning of each and every build. This also reduces the need to bloat the base image with configuration or software required by only one or two users of the base image, reducing their size and improving maintainability. Enabling changes to be made to the build and testing environments in the same repository as the application's code enhances traceability and understanding of why changes were made - the code change can form part of the same commit as the environmental change required to support it. These tools have only basic support for dependencies in other containers (for example, a database used for integration testing), and require the configuration of other tools such as Dockerize to ensure that dependencies are ready for use before they are used. This does not take advantage of images' built-in health checks and the benefits this mechanism has, such as a warm-up period. Furthermore, this leaves the developer to manually manage transitive dependencies between these containers, and all of the limitations with regard to the images used for the build environment discussed above apply equally to dependency images. These tools don't provide time-saving functionality such as automatically configuring proxies at image build time and in the container . As these tools are designed to run the build and only the build in exactly the same way every time, they do not support passing additional arguments to the task, making it difficult to change options for tasks that may be helpful during development, such as enabling a debugger or more verbose logging. These tools don't support easily mounting the local working copy into the build container, which means they can't be used for tasks that rely on detecting changes to code, such as a continuous unit test task. These tools don't have a way to easily codify and share tasks not used in the build but used by developers, such as a task that spins up the app with stubbed dependencies.","title":"...CI tools with a local runner?"},{"location":"Comparison.html#vagrant","text":"Vagrant's use of virtual machines means that it is very heavyweight, making it difficult to run multiple projects' environments at once. This is especially problematic on CI servers where we'd like to run multiple builds in parallel. Furthermore, the long-lived nature of virtual machines means that it's very easy for a developer's machine to get out of sync with the desired configuration, and nothing automatically re-provisions the machine when the configuration is changed - a developer has to remember to re-run the provisioning step if the configuration changes.","title":"...Vagrant?"},{"location":"GettingStarted.html","text":"Getting started tutorial \u00b6 In this tutorial, we'll create a TypeScript-based API that makes calls to another API and uses Yarn to manage NPM packages, and use batect to manage our development environment and tasks. This tutorial is based on the TypeScript sample project , and assumes some basic familiarity with Docker and Yarn. It should take 15-20 minutes to complete. Installation \u00b6 Before you begin, follow the setup instructions to setup batect. First task \u00b6 Let's start by defining our very first task. As is tradition, we'll be creating a \"hello world\" task. In batect, there are two major concepts: Tasks define commands to run and how to run them - for example, building your application, running tests or deploying your application. Containers define the environment tasks run in - for example, the Docker image used, the folders mounted from your local machine and the ports exposed back to your local machine. Both tasks and containers are defined in a YAML configuration file, normally called batect.yml . Let's start by defining our build environment container, build-env : containers : build-env : image : node:14.3.0 build-env uses the publicly-available node image, and specifies the particular version of the image to use. Tip It's a good idea to specify a particular image tag (eg. 14.3.0 in our example above) rather than using latest - this ensures everyone using your configuration runs the same image. We can use that container to define our hello-world task: containers : build-env : image : node:14.3.0 tasks : hello-world : description : Say hello to everyone run : container : build-env command : echo 'Hello world!' Then we can run our task with ./batect hello-world : Running hello-world... build-env: running echo 'Hello world!' Hello world! hello-world finished with exit code 0 in 1.2s. Congratulations! You've successfully configured and run your first batect task. It's worth spending a moment to explain what batect just did: First, batect loaded our configuration from batect.yml . It then checked if the node:14.3.0 image had already been pulled, and if it was not already pulled, pulled it. Next, it started our build-env container, which ran our hello world command. Once the container finished, it then cleaned up the container, leaving nothing running. There's one more thing we can check: ./batect --list-tasks . --list-tasks doesn't run a task - instead, it prints all the available tasks in our configuration file, including any description or group . Let's try running ./batect --list-tasks (or ./batect -T for short) now: Available tasks: - hello-world: Say hello to everyone There's nothing too surprising here, given we just created our configuration file. However, as our project grows, this can be very useful for someone who is unfamiliar with our project and wants to understand what tasks they can perform. First running application \u00b6 So we have our first task, but it's not exactly earth-shattering. Let's fix that by creating our TypeScript application. Normally, we could run yarn init and then yarn add typescript to do this, but then we're using the version of Yarn installed on our machine, if there even is one. It would be much better if we could use the version of Yarn available in our build-env container - then we don't need to install anything, and we don't have to worry about using different versions. To do that, let's create a shell task that starts a shell in our build environment: # ... other configuration omitted for clarity tasks : shell : description : Start a shell in the development environment run : container : build-env command : bash We can run this with ./batect shell , then run yarn init . and yarn add typescript to create a package.json with a reference to TypeScript. However, if you exit the shell with exit , after batect finishes cleaning up, you'll notice there's no package.json in our project directory. What happened to package.json ? By default, containers started with batect share nothing with the host machine, so package.json was lost when the container was removed by batect. The benefit of this is that containers are as isolated as possible, making tasks run consistently across different machines, even different operating systems. However, complete isolation isn't particularly useful - we need to keep these files around, and we'll need to be able to share our source code with the container soon as well. Let's mount our project directory into build-env with volumes : containers : build-env : image : node:14.3.0 volumes : - local : . container : /code options : cached working_directory : /code # ... tasks omitted for clarity With this change, when build-env starts, the project directory (the directory containing batect.yml ) will be mounted into the container at /code . Setting working_directory to /code means that the container will start in that directory by default. If you start a shell with ./batect shell and run yarn init . and yarn add typescript again, you'll notice that this time, package.json has been saved to your local machine. Tip If you're using macOS or Windows, you may have noticed that yarn add typescript took longer than normal. This is due to the overhead introduced by using node_modules from your local machine inside the container. Unfortunately, the performance of Docker volume mounts on macOS and Windows isn't great, and even with options: cached , the difference can be noticeable. The solution is to use a batect cache for the node_modules folder, for example: containers : build-env : image : node:14.3.0 volumes : - local : . container : /code options : cached - type : cache container : /code/node_modules name : node_modules working_directory : /code This cache persists between each task run and doesn't incur the same performance penalty as mounting a local directory. There's more details about this in the I/O performance section of the documentation. With that out of the way, let's create a basic HTTP API. Create a file called index.ts in the same directory as our batect.yml with the following contents: import * as express from \"express\" ; const app = express (); const port = 8080 ; app . get ( \"/\" , ( req , res ) => { res . send ( \"Hello from the API!\" ); }); app . listen ( port , () => { console . log ( `Listening on port ${ port } .` ); }); We'll need a few more Yarn packages - start another shell and run yarn add @types/express express ts-node to add the remaining dependencies. Let's run our application and see it in action. Add a run task to batect.yml : tasks : run : description : Run the application run : container : build-env command : yarn exec ts-node index.ts ports : - local : 8080 container : 8080 # ... other configuration omitted for clarity Our command uses Yarn and ts-node to run our TypeScript application, and maps port 8080 on our local machine to port 8080 on the container. This means that if we go to http://localhost:8080 on our local machine, we'll see our \"Hello from the API!\" message. batect also supports mapping ports in container definitions, however, given we only need the port when running the application, we've mapped the port as part of the task definition. Both have exactly the same end result. Note We're using ts-node in this tutorial because it's simple and convenient. A production-grade application would compile TypeScript down to JavaScript using tsc and run it using node . We'll change this below. We're pretty much done now - we can run our application in a consistent, isolated environment with a single command: ./batect run . However, there's one more thing we should do to make it easy for others to start using our project. With the current setup, people using our project will need to run ./batect shell and then run yarn install to download the NPM packages we're using. It would be much better if there was a batect task they could run that did this for them, so let's add one: tasks : setup : description : Install dependencies needed to build and run the application run : container : build-env command : yarn install # ... other configuration omitted for clarity Now, when someone wants to start using our project, they just need to run ./batect setup once, then ./batect run to start the application - easy! First dependency \u00b6 Now that we've got a basic API up and running, let's expand our API to include calling an external service - and expand our batect setup to orchestrate setting up both our application and the external service. We're going to enhance our 'hello world' message with a joke of the day. Let's start by adding the joke service to our batect.yml : containers : # ... build-env omitted for clarity joke-service : image : yesinteractive/dadjokes We'll also need to tell batect to start joke-service when it runs our application. We can do this by adding it as a dependency for the run task: tasks : run : description : Run the application dependencies : - joke-service run : container : build-env command : yarn exec ts-node index.ts ports : - local : 8080 container : 8080 Finally, we need to update our application to call the service and return the joke in our message. The joke service responds to GET / requests with jokes, so let's call that endpoint in index.ts : import fetch from \"node-fetch\" ; import * as express from \"express\" ; const app = express (); const port = 8080 ; app . get ( \"/\" , async ( req , res ) => { const response = await fetch ( \"http://joke-service\" ); if ( ! response . ok ) { res . sendStatus ( 503 ); res . send ( `Joke service call failed with HTTP ${ response . status } ( ${ response . statusText } )` ); return ; } const responseBody = await response . json (); res . send ( `Hello from the API! The joke of the day is: ${ responseBody . Joke . Opener } ${ responseBody . Joke . Punchline } ` ); }); app . listen ( port , () => { console . log ( `Listening on port ${ port } .` ); }); We now have a dependency on the node-fetch package, so run yarn add node-fetch @types/node-fetch from a shell to add it to package.json . Finally, we can run the application with ./batect run , and then open http://localhost:8080 to see our new message, complete with joke: Hello from the API! The joke of the day is: I made a belt out of watches once... It was a waist of time. You might be wondering why we didn't have to expose any ports on the joke-service container, and how we could use joke-service as a hostname to address that container. Under the hood, when batect starts a task, it also creates a Docker network and adds all containers in the task to that network. This allows them to address each other by name (eg. making HTTP requests to joke-service ) and access any port without explicitly exposing the port or exposing it on the host machine. Tip This same technique can be used to run integration or end-to-end tests against dependencies like external services or databases in consistent, isolated environments. Take a look at the sample projects for some examples of this. batect can also help manage the startup order of dependencies to reduce flakiness and retries in tests. First prerequisite \u00b6 The final major feature of batect that we'll explore is the concept of prerequisites . These allow you to declare that one task requires another to run first. For example, maybe your application needs to be compiled before it is run, some data needs to be generated before the tests are executed, or a number of tasks should be run as part of a pre-commit check. To see this in action, let's add a task to compile our TypeScript down to JavaScript: build : description : Build the application run : container : build-env command : yarn exec tsc -- --outDir build --sourceMap --strict index.ts We can now change our run task to run build and then run that built JavaScript: run : description : Run the application prerequisites : - build run : container : build-env command : yarn exec node -- build/index.js ports : - local : 8080 container : 8080 Voila! Running ./batect run now runs the build task, then starts run to use our freshly built code. Note We're using yarn exec to start node in run to workaround issues with node not responding to signals such as Ctrl+C when running in a container. There are more details on this in the Node usage section of the batect documentation, including another solution to the issue. Summary \u00b6 We've finished our whirlwind tour of batect. We can now easily setup, build and run our application in an isolated, consistent, repeatable way, and others can quickly start working with our project just by running ./batect --list-tasks . Where next? \u00b6 Take a look at the many sample projects for inspiration for your own projects Dive into the comprehensive reference for configuration options","title":"Getting started tutorial"},{"location":"GettingStarted.html#getting-started-tutorial","text":"In this tutorial, we'll create a TypeScript-based API that makes calls to another API and uses Yarn to manage NPM packages, and use batect to manage our development environment and tasks. This tutorial is based on the TypeScript sample project , and assumes some basic familiarity with Docker and Yarn. It should take 15-20 minutes to complete.","title":"Getting started tutorial"},{"location":"GettingStarted.html#installation","text":"Before you begin, follow the setup instructions to setup batect.","title":"Installation"},{"location":"GettingStarted.html#first-task","text":"Let's start by defining our very first task. As is tradition, we'll be creating a \"hello world\" task. In batect, there are two major concepts: Tasks define commands to run and how to run them - for example, building your application, running tests or deploying your application. Containers define the environment tasks run in - for example, the Docker image used, the folders mounted from your local machine and the ports exposed back to your local machine. Both tasks and containers are defined in a YAML configuration file, normally called batect.yml . Let's start by defining our build environment container, build-env : containers : build-env : image : node:14.3.0 build-env uses the publicly-available node image, and specifies the particular version of the image to use. Tip It's a good idea to specify a particular image tag (eg. 14.3.0 in our example above) rather than using latest - this ensures everyone using your configuration runs the same image. We can use that container to define our hello-world task: containers : build-env : image : node:14.3.0 tasks : hello-world : description : Say hello to everyone run : container : build-env command : echo 'Hello world!' Then we can run our task with ./batect hello-world : Running hello-world... build-env: running echo 'Hello world!' Hello world! hello-world finished with exit code 0 in 1.2s. Congratulations! You've successfully configured and run your first batect task. It's worth spending a moment to explain what batect just did: First, batect loaded our configuration from batect.yml . It then checked if the node:14.3.0 image had already been pulled, and if it was not already pulled, pulled it. Next, it started our build-env container, which ran our hello world command. Once the container finished, it then cleaned up the container, leaving nothing running. There's one more thing we can check: ./batect --list-tasks . --list-tasks doesn't run a task - instead, it prints all the available tasks in our configuration file, including any description or group . Let's try running ./batect --list-tasks (or ./batect -T for short) now: Available tasks: - hello-world: Say hello to everyone There's nothing too surprising here, given we just created our configuration file. However, as our project grows, this can be very useful for someone who is unfamiliar with our project and wants to understand what tasks they can perform.","title":"First task"},{"location":"GettingStarted.html#first-running-application","text":"So we have our first task, but it's not exactly earth-shattering. Let's fix that by creating our TypeScript application. Normally, we could run yarn init and then yarn add typescript to do this, but then we're using the version of Yarn installed on our machine, if there even is one. It would be much better if we could use the version of Yarn available in our build-env container - then we don't need to install anything, and we don't have to worry about using different versions. To do that, let's create a shell task that starts a shell in our build environment: # ... other configuration omitted for clarity tasks : shell : description : Start a shell in the development environment run : container : build-env command : bash We can run this with ./batect shell , then run yarn init . and yarn add typescript to create a package.json with a reference to TypeScript. However, if you exit the shell with exit , after batect finishes cleaning up, you'll notice there's no package.json in our project directory. What happened to package.json ? By default, containers started with batect share nothing with the host machine, so package.json was lost when the container was removed by batect. The benefit of this is that containers are as isolated as possible, making tasks run consistently across different machines, even different operating systems. However, complete isolation isn't particularly useful - we need to keep these files around, and we'll need to be able to share our source code with the container soon as well. Let's mount our project directory into build-env with volumes : containers : build-env : image : node:14.3.0 volumes : - local : . container : /code options : cached working_directory : /code # ... tasks omitted for clarity With this change, when build-env starts, the project directory (the directory containing batect.yml ) will be mounted into the container at /code . Setting working_directory to /code means that the container will start in that directory by default. If you start a shell with ./batect shell and run yarn init . and yarn add typescript again, you'll notice that this time, package.json has been saved to your local machine. Tip If you're using macOS or Windows, you may have noticed that yarn add typescript took longer than normal. This is due to the overhead introduced by using node_modules from your local machine inside the container. Unfortunately, the performance of Docker volume mounts on macOS and Windows isn't great, and even with options: cached , the difference can be noticeable. The solution is to use a batect cache for the node_modules folder, for example: containers : build-env : image : node:14.3.0 volumes : - local : . container : /code options : cached - type : cache container : /code/node_modules name : node_modules working_directory : /code This cache persists between each task run and doesn't incur the same performance penalty as mounting a local directory. There's more details about this in the I/O performance section of the documentation. With that out of the way, let's create a basic HTTP API. Create a file called index.ts in the same directory as our batect.yml with the following contents: import * as express from \"express\" ; const app = express (); const port = 8080 ; app . get ( \"/\" , ( req , res ) => { res . send ( \"Hello from the API!\" ); }); app . listen ( port , () => { console . log ( `Listening on port ${ port } .` ); }); We'll need a few more Yarn packages - start another shell and run yarn add @types/express express ts-node to add the remaining dependencies. Let's run our application and see it in action. Add a run task to batect.yml : tasks : run : description : Run the application run : container : build-env command : yarn exec ts-node index.ts ports : - local : 8080 container : 8080 # ... other configuration omitted for clarity Our command uses Yarn and ts-node to run our TypeScript application, and maps port 8080 on our local machine to port 8080 on the container. This means that if we go to http://localhost:8080 on our local machine, we'll see our \"Hello from the API!\" message. batect also supports mapping ports in container definitions, however, given we only need the port when running the application, we've mapped the port as part of the task definition. Both have exactly the same end result. Note We're using ts-node in this tutorial because it's simple and convenient. A production-grade application would compile TypeScript down to JavaScript using tsc and run it using node . We'll change this below. We're pretty much done now - we can run our application in a consistent, isolated environment with a single command: ./batect run . However, there's one more thing we should do to make it easy for others to start using our project. With the current setup, people using our project will need to run ./batect shell and then run yarn install to download the NPM packages we're using. It would be much better if there was a batect task they could run that did this for them, so let's add one: tasks : setup : description : Install dependencies needed to build and run the application run : container : build-env command : yarn install # ... other configuration omitted for clarity Now, when someone wants to start using our project, they just need to run ./batect setup once, then ./batect run to start the application - easy!","title":"First running application"},{"location":"GettingStarted.html#first-dependency","text":"Now that we've got a basic API up and running, let's expand our API to include calling an external service - and expand our batect setup to orchestrate setting up both our application and the external service. We're going to enhance our 'hello world' message with a joke of the day. Let's start by adding the joke service to our batect.yml : containers : # ... build-env omitted for clarity joke-service : image : yesinteractive/dadjokes We'll also need to tell batect to start joke-service when it runs our application. We can do this by adding it as a dependency for the run task: tasks : run : description : Run the application dependencies : - joke-service run : container : build-env command : yarn exec ts-node index.ts ports : - local : 8080 container : 8080 Finally, we need to update our application to call the service and return the joke in our message. The joke service responds to GET / requests with jokes, so let's call that endpoint in index.ts : import fetch from \"node-fetch\" ; import * as express from \"express\" ; const app = express (); const port = 8080 ; app . get ( \"/\" , async ( req , res ) => { const response = await fetch ( \"http://joke-service\" ); if ( ! response . ok ) { res . sendStatus ( 503 ); res . send ( `Joke service call failed with HTTP ${ response . status } ( ${ response . statusText } )` ); return ; } const responseBody = await response . json (); res . send ( `Hello from the API! The joke of the day is: ${ responseBody . Joke . Opener } ${ responseBody . Joke . Punchline } ` ); }); app . listen ( port , () => { console . log ( `Listening on port ${ port } .` ); }); We now have a dependency on the node-fetch package, so run yarn add node-fetch @types/node-fetch from a shell to add it to package.json . Finally, we can run the application with ./batect run , and then open http://localhost:8080 to see our new message, complete with joke: Hello from the API! The joke of the day is: I made a belt out of watches once... It was a waist of time. You might be wondering why we didn't have to expose any ports on the joke-service container, and how we could use joke-service as a hostname to address that container. Under the hood, when batect starts a task, it also creates a Docker network and adds all containers in the task to that network. This allows them to address each other by name (eg. making HTTP requests to joke-service ) and access any port without explicitly exposing the port or exposing it on the host machine. Tip This same technique can be used to run integration or end-to-end tests against dependencies like external services or databases in consistent, isolated environments. Take a look at the sample projects for some examples of this. batect can also help manage the startup order of dependencies to reduce flakiness and retries in tests.","title":"First dependency"},{"location":"GettingStarted.html#first-prerequisite","text":"The final major feature of batect that we'll explore is the concept of prerequisites . These allow you to declare that one task requires another to run first. For example, maybe your application needs to be compiled before it is run, some data needs to be generated before the tests are executed, or a number of tasks should be run as part of a pre-commit check. To see this in action, let's add a task to compile our TypeScript down to JavaScript: build : description : Build the application run : container : build-env command : yarn exec tsc -- --outDir build --sourceMap --strict index.ts We can now change our run task to run build and then run that built JavaScript: run : description : Run the application prerequisites : - build run : container : build-env command : yarn exec node -- build/index.js ports : - local : 8080 container : 8080 Voila! Running ./batect run now runs the build task, then starts run to use our freshly built code. Note We're using yarn exec to start node in run to workaround issues with node not responding to signals such as Ctrl+C when running in a container. There are more details on this in the Node usage section of the batect documentation, including another solution to the issue.","title":"First prerequisite"},{"location":"GettingStarted.html#summary","text":"We've finished our whirlwind tour of batect. We can now easily setup, build and run our application in an isolated, consistent, repeatable way, and others can quickly start working with our project just by running ./batect --list-tasks .","title":"Summary"},{"location":"GettingStarted.html#where-next","text":"Take a look at the many sample projects for inspiration for your own projects Dive into the comprehensive reference for configuration options","title":"Where next?"},{"location":"SampleProjects.html","text":"Sample projects \u00b6 There are a number of projects that demonstrate the use of batect: batect-sample-cypress : demonstrates using Cypress to perform UI testing of an application batect-sample-golang : demonstrates a setup for Golang and Circle CI batect-sample-java : demonstrates a setup for Java, Gradle, Travis CI, including integration and journey testing as well as pushing images to Docker Hub batect-sample-python : demonstrates a setup for Python batect-sample-ruby : demonstrates a setup for Ruby and Travis CI, including integration and journey testing batect-sample-seq : demonstrates a setup using Seq to capture and display logs from containers batect-sample-typescript : demonstrates a setup for TypeScript and GitHub Actions batect-terraform-gcp : demonstrates a setup for provisioning resources on GCP with Terraform and deploying an app to Kubernetes weekly-meetups : demonstrates a setup for Clojure and Leiningen","title":"Sample projects"},{"location":"SampleProjects.html#sample-projects","text":"There are a number of projects that demonstrate the use of batect: batect-sample-cypress : demonstrates using Cypress to perform UI testing of an application batect-sample-golang : demonstrates a setup for Golang and Circle CI batect-sample-java : demonstrates a setup for Java, Gradle, Travis CI, including integration and journey testing as well as pushing images to Docker Hub batect-sample-python : demonstrates a setup for Python batect-sample-ruby : demonstrates a setup for Ruby and Travis CI, including integration and journey testing batect-sample-seq : demonstrates a setup using Seq to capture and display logs from containers batect-sample-typescript : demonstrates a setup for TypeScript and GitHub Actions batect-terraform-gcp : demonstrates a setup for provisioning resources on GCP with Terraform and deploying an app to Kubernetes weekly-meetups : demonstrates a setup for Clojure and Leiningen","title":"Sample projects"},{"location":"Setup.html","text":"Quick start \u00b6 The batect and batect.cmd scripts are designed to be committed alongside your project, and not installed globally. Committing them alongside your code improves consistency within your team, as everyone uses the same version of batect. They will automatically pull down the correct version of batect for your operating system. Download the latest version of batect and batect.cmd from the releases page , and copy them into your project. Note that you only need the scripts - you don't need to download batect.jar . If you're on Linux or macOS, make sure the script is executable: run chmod +x batect . Create your batect.yml to define your tasks and the environments they run in: Take a look at the sample projects for inspiration Dive straight into the configuration file reference Follow the getting started tutorial Or, if you're using another tool already and want to switch to batect, batectify by @ineffyble can convert files from other tools to batect's format Requirements \u00b6 batect requires Docker 18.03.1 or newer, Java 8 or newer (although this requirement will be removed before v1.0), and: On Linux and macOS: Bash and curl On Windows: Windows 10 batect supports both Linux and Windows containers. A 64-bit version of Java is required on Windows.","title":"Setup"},{"location":"Setup.html#quick-start","text":"The batect and batect.cmd scripts are designed to be committed alongside your project, and not installed globally. Committing them alongside your code improves consistency within your team, as everyone uses the same version of batect. They will automatically pull down the correct version of batect for your operating system. Download the latest version of batect and batect.cmd from the releases page , and copy them into your project. Note that you only need the scripts - you don't need to download batect.jar . If you're on Linux or macOS, make sure the script is executable: run chmod +x batect . Create your batect.yml to define your tasks and the environments they run in: Take a look at the sample projects for inspiration Dive straight into the configuration file reference Follow the getting started tutorial Or, if you're using another tool already and want to switch to batect, batectify by @ineffyble can convert files from other tools to batect's format","title":"Quick start"},{"location":"Setup.html#requirements","text":"batect requires Docker 18.03.1 or newer, Java 8 or newer (although this requirement will be removed before v1.0), and: On Linux and macOS: Bash and curl On Windows: Windows 10 batect supports both Linux and Windows containers. A 64-bit version of Java is required on Windows.","title":"Requirements"},{"location":"TaskLifecycle.html","text":"The task lifecycle \u00b6 When batect runs a task, there are a number of steps that it follows: First, it determines which tasks to run and what order to run them in, based on the prerequisites of the requested task and any prerequisites of those prerequisites and so on. Next, for each task, it determines what containers need to be started for that task, based on the dependency relationships between containers. Then, it then creates a Docker network for the task, and runs cache initialisation if required. In parallel to setting up the network and caches, for every container that makes up the task: It builds or pulls the image required for this container It waits for the task network to be ready It waits for cache initialisation to complete, if this container mounts any caches It waits for any containers that this container depends on to be ready - so each dependency must have reported as healthy and completed all setup commands It starts the container and the container's command It waits for the container to report as healthy It runs any setup commands , one at a time in the order provided Once all setup commands have completed, any dependent containers can start. Once the main container exits, batect then cleans up the containers. This means that, for every container: It waits for all containers that depend on this one to stop It stops this container It removes this container It cleans up any temporary files or folders created for this container Once all containers are removed, the task network is removed and then the task is complete.","title":"Task lifecycle"},{"location":"TaskLifecycle.html#the-task-lifecycle","text":"When batect runs a task, there are a number of steps that it follows: First, it determines which tasks to run and what order to run them in, based on the prerequisites of the requested task and any prerequisites of those prerequisites and so on. Next, for each task, it determines what containers need to be started for that task, based on the dependency relationships between containers. Then, it then creates a Docker network for the task, and runs cache initialisation if required. In parallel to setting up the network and caches, for every container that makes up the task: It builds or pulls the image required for this container It waits for the task network to be ready It waits for cache initialisation to complete, if this container mounts any caches It waits for any containers that this container depends on to be ready - so each dependency must have reported as healthy and completed all setup commands It starts the container and the container's command It waits for the container to report as healthy It runs any setup commands , one at a time in the order provided Once all setup commands have completed, any dependent containers can start. Once the main container exits, batect then cleans up the containers. This means that, for every container: It waits for all containers that depend on this one to stop It stops this container It removes this container It cleans up any temporary files or folders created for this container Once all containers are removed, the task network is removed and then the task is complete.","title":"The task lifecycle"},{"location":"config/ConfigVariables.html","text":"Config variables \u00b6 Note This page reflects the options available in the most recent version of batect. Config variables allow you simplify your configuration file, and document and codify the different options available to a developer using your tasks. They are useful for a number of use cases: Reducing duplication in configuration files Simplifying management of developer-specific preferences (eg. a developer's preferred log output level) Simplifying management of sets of environment-specific settings (eg. managing sets of test environment connection settings for a CI server) Config variables can be used anywhere expressions are supported. Reference config variables with the syntax <name or <{name} . Values \u00b6 Values for config variables are taken from the following sources, with higher values taking precedence: a value provided on the command line with --config-var <name>=<value> a value specified in a config variables file, either the default batect.local.yml or specified with --config-vars-file the default value If a variable is referenced but no value is available for it, an error occurs. Built-in config variables \u00b6 There is one built-in config variable: batect.project_directory \u00b6 Contains the full path to the directory containing the root configuration file in use. Normally, this is the directory containing batect.yml unless the configuration file has been overridden with the --config-file / -f command line option . This is particularly useful in configuration files imported into the project with include . For example, if /my-project/a.yml contains: include : - includes/b.yml And /my-project/includes/b.yml contains: containers : my-container : image : alpine:1.2.3 volumes : - local : <{batect.project_directory}/scripts container : /code/scripts Then the directory /my-project/scripts will be mounted into the my-container container at /code/scripts . Definition \u00b6 Each config variable definition is made up of: description \u00b6 A human-readable description of the variable. default \u00b6 The default value of the variable. Examples \u00b6 Config variable with no description or default value \u00b6 config_variables : log_level : {} {} is the YAML syntax for an empty object. Config variable with description and default value \u00b6 config_variables : log_level : description : Log level to use for application default : debug","title":"Config Variables"},{"location":"config/ConfigVariables.html#config-variables","text":"Note This page reflects the options available in the most recent version of batect. Config variables allow you simplify your configuration file, and document and codify the different options available to a developer using your tasks. They are useful for a number of use cases: Reducing duplication in configuration files Simplifying management of developer-specific preferences (eg. a developer's preferred log output level) Simplifying management of sets of environment-specific settings (eg. managing sets of test environment connection settings for a CI server) Config variables can be used anywhere expressions are supported. Reference config variables with the syntax <name or <{name} .","title":"Config variables"},{"location":"config/ConfigVariables.html#values","text":"Values for config variables are taken from the following sources, with higher values taking precedence: a value provided on the command line with --config-var <name>=<value> a value specified in a config variables file, either the default batect.local.yml or specified with --config-vars-file the default value If a variable is referenced but no value is available for it, an error occurs.","title":"Values"},{"location":"config/ConfigVariables.html#built-in-config-variables","text":"There is one built-in config variable:","title":"Built-in config variables"},{"location":"config/ConfigVariables.html#batectproject_directory","text":"Contains the full path to the directory containing the root configuration file in use. Normally, this is the directory containing batect.yml unless the configuration file has been overridden with the --config-file / -f command line option . This is particularly useful in configuration files imported into the project with include . For example, if /my-project/a.yml contains: include : - includes/b.yml And /my-project/includes/b.yml contains: containers : my-container : image : alpine:1.2.3 volumes : - local : <{batect.project_directory}/scripts container : /code/scripts Then the directory /my-project/scripts will be mounted into the my-container container at /code/scripts .","title":"batect.project_directory"},{"location":"config/ConfigVariables.html#definition","text":"Each config variable definition is made up of:","title":"Definition"},{"location":"config/ConfigVariables.html#description","text":"A human-readable description of the variable.","title":"description"},{"location":"config/ConfigVariables.html#default","text":"The default value of the variable.","title":"default"},{"location":"config/ConfigVariables.html#examples","text":"","title":"Examples"},{"location":"config/ConfigVariables.html#config-variable-with-no-description-or-default-value","text":"config_variables : log_level : {} {} is the YAML syntax for an empty object.","title":"Config variable with no description or default value"},{"location":"config/ConfigVariables.html#config-variable-with-description-and-default-value","text":"config_variables : log_level : description : Log level to use for application default : debug","title":"Config variable with description and default value"},{"location":"config/Containers.html","text":"Container definitions \u00b6 Note This page reflects the options available in the most recent version of batect. There are a number of configuration options for containers: image : image to use for this container. One of image or build_directory is required. build_directory : path to a directory containing a Dockerfile to build and use for this container. One of image or build_directory is required. build_args : list of build args to use when building the image in build_directory dockerfile : Dockerfile to use when building the image in build_directory command : command to run when the container starts entrypoint : entrypoint to use to run the container's command environment : environment variables for the container working_directory : working directory for the container's command volumes : volume mounts to create for the container devices : device mounts to create for the container ports : ports to expose from the container to the host machine dependencies : other containers to start before starting this container health_check : health check configuration for the container run_as_current_user : configuration for 'run as current user' mode setup_commands : commands to run inside the container after it has become healthy but before dependent containers start privileged : enable privileged mode for the container capabilities_to_add : additional capabilities to grant to the container capabilities_to_drop : additional capabilities to remove from the container enable_init_process : enable Docker's init process for the container additional_hostnames : other hostnames to associate with the container, in addition to the container's name additional_hosts : extra entries to add to /etc/hosts inside the container log_driver : Docker log driver to use when running the container log_options : additional options for the log driver in use additional_hostnames \u00b6 Equivalent Docker CLI option : --network-alias to docker run , equivalent Docker Compose option : extra_hosts List of hostnames to associate with this container, in addition to the default hostname (the name of the container). For example, my-container will be reachable by other containers running as part of the same task at both my-container and other-name with the following configuration: containers : my-container : additional_hostnames : - other-name additional_hosts \u00b6 Equivalent Docker CLI option : --add-host to docker run , equivalent Docker Compose option : networks.aliases Additional hostnames to add to /etc/hosts in the container. Equivalent to --add-host option for docker run . For example, to configure processes inside my-container to resolve database.example.com to 1.2.3.4 : containers : my-container : additional_hosts : database.example.com : 1.2.3.4 build_args \u00b6 Equivalent Docker CLI option : --build-arg to docker build , equivalent Docker Compose option : build.args List of build args (in name: value format) to use when building the image in build_directory . Values can be expressions . Each build arg must be defined in the Dockerfile with an ARG instruction otherwise the value provided will have no effect. Warning Use caution when using build args for secret values. Build arg values can be revealed by anyone with a copy of the image with the docker history command. For example, to set the message build arg to hello : containers : my-container : build_args : message : hello build_directory \u00b6 Equivalent Docker CLI option : argument to docker build , equivalent Docker Compose option : build or build.context Path (relative to the configuration file's directory) to a directory containing a Dockerfile to build and use as an image for this container. One of image or build_directory is required. Value can be an expression . On Windows, build_directory can use either Windows-style ( path\\to\\thing ) or Unix-style ( path/to/thing ) paths, but for compatibility with users running on other operating systems, using Unix-style paths is recommended. The image can be overridden when running a task with --override-image . The Docker build cache is used during the build process, so if the image definition has not changed since the last build, the image will not be rebuilt, saving time. For example, running the container my_container from the following configuration will first build the Dockerfile in the .batect/my-container directory, then run the resulting image: containers : my-container : build_directory : .batect/my-container capabilities_to_add and capabilities_to_drop \u00b6 Equivalent Docker CLI option : --cap-add / --cap-drop to docker run , equivalent Docker Compose option : cap_add / cap_drop List of capabilities to add or drop for the container. For example: containers : my-container : capabilities_to_add : - CAP_SYS_ADMIN capabilities_to_drop : - CAP_KILL command \u00b6 Equivalent Docker CLI option : argument to docker run , equivalent Docker Compose option : command Command to run when the container starts. If not provided, the default command for the image will be run. Both of these can be overridden for an individual task by specifying a command at the task level . For example, running the container my-container from the following configuration will run the command echo 'Hello world' , and not the default command specified in the my-image image: containers : my-container : image : my-image command : echo 'Hello world' Note Keep in mind that this command is passed to the image's ENTRYPOINT , just like it would when using docker run <image> <command> directly. This means that if the entrypoint is not set or is not a shell, standard shell syntax features like $MY_ENVIRONMENT_VARIABLE and && might not work. See the Docker docs for CMD and ENTRYPOINT for more details. If you would like to use shell syntax features in your command, you have four options: Create a shell script and invoke that instead of specifying the command directly. Wrap your command in a shell invocation. For example, if your command is echo hello && echo world , set command to sh -c 'echo hello && echo world' . Set the entrypoint in the image to a shell. For example: ENTRYPOINT [ \"/bin/sh\" , \"-c\" ] Set the entrypoint for the container to a shell. For example: containers : container-1 : command : \"'echo hello && echo world'\" # Single quotes so that whole command is treated as a single argument when passed to sh, double quotes so that YAML preserves the single quotes entrypoint : /bin/sh -c Note that for both options 3 and 4, you must quote the command so that it is passed to sh -c as a single argument (we want the final command line to be sh -c 'echo hello && echo world' , not sh -c echo hello && echo world ). dependencies \u00b6 Equivalent Docker CLI option : none, equivalent Docker Compose option : depends_on (behaviour differs) List of other containers that should be started and healthy before starting this container. If a dependency's image does not contain a health check , then as soon as it has started, it is considered to be healthy. See this page for more information on how to ensure dependencies are ready before starting containers that depend on them. For example, running the container application from the following configuration will first run the database container and wait for it to become healthy before starting the application container: containers : application : build_directory : .batect/application dependencies : - database database : build_directory : .batect/database devices \u00b6 Equivalent Docker CLI option : --device to docker run , equivalent Docker Compose option : devices List of device mounts to create for the container. Two formats are supported: local:container or local:container:options format An expanded format: containers : my-container : ... devices : # This is equivalent to /dev/sda:/dev/disk:r - local : /dev/sda container : /dev/disk options : r Note that the local device mounts will be different for Windows and Unix-like hosts. See the Docker guide for adding host devices to containers for more information. dockerfile \u00b6 Equivalent Docker CLI option : --file to docker build , equivalent Docker Compose option : build.dockerfile Dockerfile (relative to build_directory ) to use when building the image in build_directory . Defaults to Dockerfile if not set. The Dockerfile must be within build_directory . dockerfile must always be specified with Unix-style ( path/to/thing ) paths, even when running on Windows. For example, running the container my_container from the following configuration will build the image given by the Dockerfile stored at .batect/my-container/my-custom-Dockerfile : containers : my-container : build_directory : .batect/my-container dockerfile : my-custom-Dockerfile enable_init_process \u00b6 Equivalent Docker CLI option : --init to docker run , equivalent Docker Compose option : init Set to true to pass the --init flag when running the container. Defaults to false . This creates the container with a simple PID 1 process to handle the responsibilities of the init system, which is required for some applications to behave correctly. Read this article to understand more about the behaviour of different processes running as PID 1 and why this flag was introduced. For example, running the container build-env from the following configuration will launch a container that uses the node:10.10.0-alpine image with Docker's default init process as PID 1: containers : build-env : image : node:10.10.0-alpine enable_init_process : true entrypoint \u00b6 Equivalent Docker CLI option : --entrypoint to docker run , equivalent Docker Compose option : entrypoint Entrypoint to use to run command or the image's default command if command is not provided. If not provided, the default entrypoint for the image will be used. Both of these can be overridden for an individual task by specifying an entrypoint at the task level . See the Docker docs for CMD and ENTRYPOINT for more information on how the entrypoint is used. batect will always convert the entrypoint provided here to the exec form when passed to Docker. For example, the container my-container from the following configuration will use sh -c as its entrypoint and ignore the default entrypoint set in my-image : containers : my-container : image : my-image entrypoint : sh -c environment \u00b6 Equivalent Docker CLI option : --env to docker run , equivalent Docker Compose option : environment List of environment variables (in name: value format) for the container. Values can be expressions . Example \u00b6 Let's assume we have the following configuration: containers : build-env : image : ruby:2.4.3 environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the container build-env will launch a container that uses the ruby:2.4.3 image with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variable SUPER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container. TERM \u00b6 The TERM environment variable, if set on the host, is always automatically passed through to the container. This ensures that features such as coloured output continue to work correctly inside the container. Proxy-related environment variables \u00b6 Proxy-related environment variables, if set on the host, are passed through to the container at build and run time, but are not used for image pulls. If a proxy-related environment variable is defined on the container's configuration, it takes precedence over the host-provided value. See this page for more information on using batect with proxies. health_check \u00b6 Equivalent Docker CLI option : --health-cmd , --health-interval , --health-retries and --health-start-period to docker run , equivalent Docker Compose option : healthcheck Overrides the health check configuration specified in the image: command \u00b6 The command to run to check the health of the container. If this command exits with code 0, the container is considered healthy, otherwise the container is considered unhealthy. retries \u00b6 The number of times to perform the health check before considering the container unhealthy. interval \u00b6 The interval between runs of the health check. Accepts values such as 2s (two seconds) or 1m (one minute). start_period \u00b6 The time to wait before failing health checks count against the retry count. During this period, the health check still runs, and if the check succeeds during this time, the container is immediately considered healthy. Accepts values such as 2s (two seconds) or 1m (one minute). Example \u00b6 The following configuration uses a fictional is-healthy command every two seconds to determine if the container is healthy. After an initial three second waiting period, the container will be declared unhealthy if it fails the health check five more times. containers : my-container : health_check : command : is-healthy localhost:8080 interval : 2s retries : 5 start_period : 3s image \u00b6 Equivalent Docker CLI option : argument to docker run , equivalent Docker Compose option : image Image name (in standard Docker image reference format) to use for this container. One of image or build_directory is required. If the image has not already been pulled, batect will pull it before starting the container. The image can be overridden from the command line when running a task with --override-image . For example, the container my-container from the following configuration will use the ruby:2.4.3 image: containers : my-container : image : ruby:2.4.3 Tip It is highly recommended that you specify a specific image version, and not use latest , to ensure that the same image is used everywhere. For example, use alpine:3.7 , not alpine or alpine:latest . log_driver \u00b6 Equivalent Docker CLI option : --log-driver to docker run , equivalent Docker Compose option : logging.driver The Docker log driver to use when running the container. Defaults to json-file if not set. A full list of built-in log drivers is available in the logging section of Docker documentation , and logging plugins can be used as well. Options for the log driver can be provided with log_options . For example, the container my-container from the following configuration will use the syslog log driver: containers : my-container : log_driver : syslog Warning Some log drivers do not support streaming container output to the console, as described in the limitations section of Docker's logging documentation . If the selected log driver does not support streaming container output to the console, you will see error messages similar to Error attaching: configured logging driver does not support reading in batect's output. This does not affect the execution of the task, which will run to completion as per normal. log_options \u00b6 Equivalent Docker CLI option : --log-opt to docker run , equivalent Docker Compose option : logging.options Options to provide to the Docker log driver used when running the container. For example, to set the tag used to identify the container in logs : containers : my-container : log_options : tag : \"my-container\" The options available for each log driver are described in the Docker documentation for that log driver, such as this page for the json-file driver. ports \u00b6 Equivalent Docker CLI option : --publish to docker run , equivalent Docker Compose option : ports List of ports to make available to the host machine. Three formats are supported: local:container or local:container/protocol format For example, 1234:5678 or 1234:5678/tcp will make TCP port 5678 inside the container available on the host machine at TCP port 1234, and 1234:5678/udp will make UDP port 5678 inside the container available on the host machine at UDP port 1234. local_from-local_to:container_from:container-to or local_from-local_to:container_from:container-to/protocol format For example, 1000-1001:2025-2026 or 1000-1001:2025-2026/tcp will make TCP port 2025 inside the container available on the host machine at TCP port 1000, and TCP port 2026 inside the container available on the host machine at TCP port 1001. An expanded format: containers : my-container : ... ports : # This is equivalent to 1234:5678 or 1234:5678/tcp - local : 1234 container : 5678 # This is equivalent to 3000:4000/udp - local : 3000 container : 4000 protocol : udp # This is equivalent to 1000-1001:2025-2026 or 1000-1001:2025-2026/tcp - local : 1000-1001 container : 2025-2026 # This is equivalent to 5000-5001:6025-6026/udp - local : 5000-5001 container : 6025-6026 protocol : udp All protocols supported by Docker are supported. The default protocol is TCP if none is provided. The port does not need to have a corresponding EXPOSE instruction in the Dockerfile. For example, the my-container container in the following configuration allows accessing port 5678 from the container on port 1234 on the host machine: container : my-container : ports : - 1234:5678 # or - local : 1234 container : 5678 Tip Exposing ports is only required if you need to access the container from the host machine. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port , even if that port is not listed in ports . For example, if a process running in the http-server container listens on port 2000, any other container in the task can access that at http-server:2000 without port 2000 being listed in ports (or an EXPOSE Dockerfile instruction). privileged \u00b6 Equivalent Docker CLI option : --privileged to docker run , equivalent Docker Compose option : privileged Set to true to run the container in privileged mode . Defaults to false . See also capabilities_to_add and capabilities_to_drop . For example, the following configuration runs the my-container container in privileged mode: containers : my-container : privileged : true run_as_current_user \u00b6 Equivalent Docker CLI option : none, equivalent Docker Compose option : none Run the container with the same UID and GID as the user running batect (rather than the user the Docker daemon runs as, which is root on Linux). This means that any files created by the container will be owned by the user running batect, rather than root. This is really only useful on Linux. On macOS, the Docker daemon runs as the currently logged-in user and so any files created in the container are owned by that user, so this is less of an issue. However, for consistency, the same configuration changes are made on both Linux and macOS. See this page for more information on the effects of this option and why it is necessary. run_as_current_user has the following options: enabled \u00b6 Set to true to enable 'run as current user' mode. Defaults to false . home_directory \u00b6 Directory to use as home directory for user inside container. Required if enabled is true , not allowed if enabled is false . This directory is automatically created by batect with the correct owner and group. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. Example \u00b6 containers : my-container : image : ruby:2.4.3 run_as_current_user : enabled : true home_directory : /home/container-user setup_commands \u00b6 Equivalent Docker CLI option : none, equivalent Docker Compose option : none List of commands to run inside the container after it has become healthy but before dependent containers start. See the task lifecycle for more information on the effects of this option. Tip It is recommended that you try to include any setup work in your image's Dockerfile wherever possible (and not use setup commands). Setup commands must be run every time the container starts whereas commands included in your image's Dockerfile only run when the image needs to be built, reducing the time taken for tasks to start. Each setup command has the following options: command \u00b6 The command to run. Required. This command is run in a similar way to the container's command , so the same limitations apply to using shell syntax such as && . working_directory \u00b6 The working directory to use for the command. If no working directory is provided, working_directory is used if it is set, otherwise the image's default working directory is used. If this container is used as the task container and the task overrides the default working directory, that override is ignored when running setup commands. The command will inherit the same environment variables as the container's command (including any specified on the task if this is the task container), runs as the same user and group as the container's command and inherits the same settings for privileged status and capabilities . Example \u00b6 Let's assume we have the following configuration: containers : database : setup_commands : - command : ./apply-migrations.sh application : dependencies : - database Running the container application will first build or pull the images for both the database and application containers. Once the image for database is ready, database will start and launch the command specified in the Dockerfile, then batect will wait for the container to report as healthy. Once database reports as healthy, it will run ./apply-migrations.sh and wait for it to finish before then starting application . volumes \u00b6 Equivalent Docker CLI option : --volume to docker run , equivalent Docker Compose option : volumes List of volume mounts to create for the container. Both local mounts (mounting a directory on the host into a container) and cache mounts are supported: Local mounts \u00b6 Two formats are supported: local:container or local:container:options format An expanded format: containers : my-container : ... volumes : # This is equivalent to .:/code:cached - local : . container : /code options : cached In both formats, the following fields are supported: local : path to the local file or directory to mount. Can be an expression when using the expanded format. Required. Relative paths will be resolved relative to the current configuration file's directory. On Windows, the local path can use either Windows-style ( path\\to\\thing ) or Unix-style ( path/to/thing ) paths, but for compatibility with users running on other operating systems, using Unix-style paths is recommended. container : path to mount the local file or directory at inside the container. Required. options : standard Docker mount options (such as ro for read-only). Optional. Using options: cached may improve performance when running on macOS and Windows hosts - see this page for further explanation. Cache mounts \u00b6 Cache mounts provide persistence between task runs without the performance overhead of mounting a directory from the host into the container. They are perfect for directories such as node_modules which contain downloaded dependencies that can safely be reused for each task run. The format for a cache mount is: containers : my-container : ... volumes : - type : cache name : node-modules container : /code/node_modules The following fields are supported: type : must be set to cache . Required. name : name of the cache, must be a valid Docker volume name. The same name can be used to share a cache between multiple containers. Required. container : path to mount the cache directory at inside the container. Required. options : standard Docker mount options (such as ro for read-only). Optional. working_directory \u00b6 Equivalent Docker CLI option : --workdir to docker run , equivalent Docker Compose option : working_dir Working directory to start the container in. If not provided, the default working directory for the image will be used. Both of these can be overridden for an individual task by specifying a working_directory at the task level . For example, the container my-container in the following configuration will start with the working directory set to /somewhere : containers : my-container : working_directory : /somewhere","title":"Containers"},{"location":"config/Containers.html#container-definitions","text":"Note This page reflects the options available in the most recent version of batect. There are a number of configuration options for containers: image : image to use for this container. One of image or build_directory is required. build_directory : path to a directory containing a Dockerfile to build and use for this container. One of image or build_directory is required. build_args : list of build args to use when building the image in build_directory dockerfile : Dockerfile to use when building the image in build_directory command : command to run when the container starts entrypoint : entrypoint to use to run the container's command environment : environment variables for the container working_directory : working directory for the container's command volumes : volume mounts to create for the container devices : device mounts to create for the container ports : ports to expose from the container to the host machine dependencies : other containers to start before starting this container health_check : health check configuration for the container run_as_current_user : configuration for 'run as current user' mode setup_commands : commands to run inside the container after it has become healthy but before dependent containers start privileged : enable privileged mode for the container capabilities_to_add : additional capabilities to grant to the container capabilities_to_drop : additional capabilities to remove from the container enable_init_process : enable Docker's init process for the container additional_hostnames : other hostnames to associate with the container, in addition to the container's name additional_hosts : extra entries to add to /etc/hosts inside the container log_driver : Docker log driver to use when running the container log_options : additional options for the log driver in use","title":"Container definitions"},{"location":"config/Containers.html#additional_hostnames","text":"Equivalent Docker CLI option : --network-alias to docker run , equivalent Docker Compose option : extra_hosts List of hostnames to associate with this container, in addition to the default hostname (the name of the container). For example, my-container will be reachable by other containers running as part of the same task at both my-container and other-name with the following configuration: containers : my-container : additional_hostnames : - other-name","title":"additional_hostnames"},{"location":"config/Containers.html#additional_hosts","text":"Equivalent Docker CLI option : --add-host to docker run , equivalent Docker Compose option : networks.aliases Additional hostnames to add to /etc/hosts in the container. Equivalent to --add-host option for docker run . For example, to configure processes inside my-container to resolve database.example.com to 1.2.3.4 : containers : my-container : additional_hosts : database.example.com : 1.2.3.4","title":"additional_hosts"},{"location":"config/Containers.html#build_args","text":"Equivalent Docker CLI option : --build-arg to docker build , equivalent Docker Compose option : build.args List of build args (in name: value format) to use when building the image in build_directory . Values can be expressions . Each build arg must be defined in the Dockerfile with an ARG instruction otherwise the value provided will have no effect. Warning Use caution when using build args for secret values. Build arg values can be revealed by anyone with a copy of the image with the docker history command. For example, to set the message build arg to hello : containers : my-container : build_args : message : hello","title":"build_args"},{"location":"config/Containers.html#build_directory","text":"Equivalent Docker CLI option : argument to docker build , equivalent Docker Compose option : build or build.context Path (relative to the configuration file's directory) to a directory containing a Dockerfile to build and use as an image for this container. One of image or build_directory is required. Value can be an expression . On Windows, build_directory can use either Windows-style ( path\\to\\thing ) or Unix-style ( path/to/thing ) paths, but for compatibility with users running on other operating systems, using Unix-style paths is recommended. The image can be overridden when running a task with --override-image . The Docker build cache is used during the build process, so if the image definition has not changed since the last build, the image will not be rebuilt, saving time. For example, running the container my_container from the following configuration will first build the Dockerfile in the .batect/my-container directory, then run the resulting image: containers : my-container : build_directory : .batect/my-container","title":"build_directory"},{"location":"config/Containers.html#capabilities_to_add-and-capabilities_to_drop","text":"Equivalent Docker CLI option : --cap-add / --cap-drop to docker run , equivalent Docker Compose option : cap_add / cap_drop List of capabilities to add or drop for the container. For example: containers : my-container : capabilities_to_add : - CAP_SYS_ADMIN capabilities_to_drop : - CAP_KILL","title":"capabilities_to_add and capabilities_to_drop"},{"location":"config/Containers.html#command","text":"Equivalent Docker CLI option : argument to docker run , equivalent Docker Compose option : command Command to run when the container starts. If not provided, the default command for the image will be run. Both of these can be overridden for an individual task by specifying a command at the task level . For example, running the container my-container from the following configuration will run the command echo 'Hello world' , and not the default command specified in the my-image image: containers : my-container : image : my-image command : echo 'Hello world' Note Keep in mind that this command is passed to the image's ENTRYPOINT , just like it would when using docker run <image> <command> directly. This means that if the entrypoint is not set or is not a shell, standard shell syntax features like $MY_ENVIRONMENT_VARIABLE and && might not work. See the Docker docs for CMD and ENTRYPOINT for more details. If you would like to use shell syntax features in your command, you have four options: Create a shell script and invoke that instead of specifying the command directly. Wrap your command in a shell invocation. For example, if your command is echo hello && echo world , set command to sh -c 'echo hello && echo world' . Set the entrypoint in the image to a shell. For example: ENTRYPOINT [ \"/bin/sh\" , \"-c\" ] Set the entrypoint for the container to a shell. For example: containers : container-1 : command : \"'echo hello && echo world'\" # Single quotes so that whole command is treated as a single argument when passed to sh, double quotes so that YAML preserves the single quotes entrypoint : /bin/sh -c Note that for both options 3 and 4, you must quote the command so that it is passed to sh -c as a single argument (we want the final command line to be sh -c 'echo hello && echo world' , not sh -c echo hello && echo world ).","title":"command"},{"location":"config/Containers.html#dependencies","text":"Equivalent Docker CLI option : none, equivalent Docker Compose option : depends_on (behaviour differs) List of other containers that should be started and healthy before starting this container. If a dependency's image does not contain a health check , then as soon as it has started, it is considered to be healthy. See this page for more information on how to ensure dependencies are ready before starting containers that depend on them. For example, running the container application from the following configuration will first run the database container and wait for it to become healthy before starting the application container: containers : application : build_directory : .batect/application dependencies : - database database : build_directory : .batect/database","title":"dependencies"},{"location":"config/Containers.html#devices","text":"Equivalent Docker CLI option : --device to docker run , equivalent Docker Compose option : devices List of device mounts to create for the container. Two formats are supported: local:container or local:container:options format An expanded format: containers : my-container : ... devices : # This is equivalent to /dev/sda:/dev/disk:r - local : /dev/sda container : /dev/disk options : r Note that the local device mounts will be different for Windows and Unix-like hosts. See the Docker guide for adding host devices to containers for more information.","title":"devices"},{"location":"config/Containers.html#dockerfile","text":"Equivalent Docker CLI option : --file to docker build , equivalent Docker Compose option : build.dockerfile Dockerfile (relative to build_directory ) to use when building the image in build_directory . Defaults to Dockerfile if not set. The Dockerfile must be within build_directory . dockerfile must always be specified with Unix-style ( path/to/thing ) paths, even when running on Windows. For example, running the container my_container from the following configuration will build the image given by the Dockerfile stored at .batect/my-container/my-custom-Dockerfile : containers : my-container : build_directory : .batect/my-container dockerfile : my-custom-Dockerfile","title":"dockerfile"},{"location":"config/Containers.html#enable_init_process","text":"Equivalent Docker CLI option : --init to docker run , equivalent Docker Compose option : init Set to true to pass the --init flag when running the container. Defaults to false . This creates the container with a simple PID 1 process to handle the responsibilities of the init system, which is required for some applications to behave correctly. Read this article to understand more about the behaviour of different processes running as PID 1 and why this flag was introduced. For example, running the container build-env from the following configuration will launch a container that uses the node:10.10.0-alpine image with Docker's default init process as PID 1: containers : build-env : image : node:10.10.0-alpine enable_init_process : true","title":"enable_init_process"},{"location":"config/Containers.html#entrypoint","text":"Equivalent Docker CLI option : --entrypoint to docker run , equivalent Docker Compose option : entrypoint Entrypoint to use to run command or the image's default command if command is not provided. If not provided, the default entrypoint for the image will be used. Both of these can be overridden for an individual task by specifying an entrypoint at the task level . See the Docker docs for CMD and ENTRYPOINT for more information on how the entrypoint is used. batect will always convert the entrypoint provided here to the exec form when passed to Docker. For example, the container my-container from the following configuration will use sh -c as its entrypoint and ignore the default entrypoint set in my-image : containers : my-container : image : my-image entrypoint : sh -c","title":"entrypoint"},{"location":"config/Containers.html#environment","text":"Equivalent Docker CLI option : --env to docker run , equivalent Docker Compose option : environment List of environment variables (in name: value format) for the container. Values can be expressions .","title":"environment"},{"location":"config/Containers.html#example","text":"Let's assume we have the following configuration: containers : build-env : image : ruby:2.4.3 environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the container build-env will launch a container that uses the ruby:2.4.3 image with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variable SUPER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container.","title":"Example"},{"location":"config/Containers.html#term","text":"The TERM environment variable, if set on the host, is always automatically passed through to the container. This ensures that features such as coloured output continue to work correctly inside the container.","title":"TERM"},{"location":"config/Containers.html#proxy-related-environment-variables","text":"Proxy-related environment variables, if set on the host, are passed through to the container at build and run time, but are not used for image pulls. If a proxy-related environment variable is defined on the container's configuration, it takes precedence over the host-provided value. See this page for more information on using batect with proxies.","title":"Proxy-related environment variables"},{"location":"config/Containers.html#health_check","text":"Equivalent Docker CLI option : --health-cmd , --health-interval , --health-retries and --health-start-period to docker run , equivalent Docker Compose option : healthcheck Overrides the health check configuration specified in the image:","title":"health_check"},{"location":"config/Containers.html#command_1","text":"The command to run to check the health of the container. If this command exits with code 0, the container is considered healthy, otherwise the container is considered unhealthy.","title":"command"},{"location":"config/Containers.html#retries","text":"The number of times to perform the health check before considering the container unhealthy.","title":"retries"},{"location":"config/Containers.html#interval","text":"The interval between runs of the health check. Accepts values such as 2s (two seconds) or 1m (one minute).","title":"interval"},{"location":"config/Containers.html#start_period","text":"The time to wait before failing health checks count against the retry count. During this period, the health check still runs, and if the check succeeds during this time, the container is immediately considered healthy. Accepts values such as 2s (two seconds) or 1m (one minute).","title":"start_period"},{"location":"config/Containers.html#example_1","text":"The following configuration uses a fictional is-healthy command every two seconds to determine if the container is healthy. After an initial three second waiting period, the container will be declared unhealthy if it fails the health check five more times. containers : my-container : health_check : command : is-healthy localhost:8080 interval : 2s retries : 5 start_period : 3s","title":"Example"},{"location":"config/Containers.html#image","text":"Equivalent Docker CLI option : argument to docker run , equivalent Docker Compose option : image Image name (in standard Docker image reference format) to use for this container. One of image or build_directory is required. If the image has not already been pulled, batect will pull it before starting the container. The image can be overridden from the command line when running a task with --override-image . For example, the container my-container from the following configuration will use the ruby:2.4.3 image: containers : my-container : image : ruby:2.4.3 Tip It is highly recommended that you specify a specific image version, and not use latest , to ensure that the same image is used everywhere. For example, use alpine:3.7 , not alpine or alpine:latest .","title":"image"},{"location":"config/Containers.html#log_driver","text":"Equivalent Docker CLI option : --log-driver to docker run , equivalent Docker Compose option : logging.driver The Docker log driver to use when running the container. Defaults to json-file if not set. A full list of built-in log drivers is available in the logging section of Docker documentation , and logging plugins can be used as well. Options for the log driver can be provided with log_options . For example, the container my-container from the following configuration will use the syslog log driver: containers : my-container : log_driver : syslog Warning Some log drivers do not support streaming container output to the console, as described in the limitations section of Docker's logging documentation . If the selected log driver does not support streaming container output to the console, you will see error messages similar to Error attaching: configured logging driver does not support reading in batect's output. This does not affect the execution of the task, which will run to completion as per normal.","title":"log_driver"},{"location":"config/Containers.html#log_options","text":"Equivalent Docker CLI option : --log-opt to docker run , equivalent Docker Compose option : logging.options Options to provide to the Docker log driver used when running the container. For example, to set the tag used to identify the container in logs : containers : my-container : log_options : tag : \"my-container\" The options available for each log driver are described in the Docker documentation for that log driver, such as this page for the json-file driver.","title":"log_options"},{"location":"config/Containers.html#ports","text":"Equivalent Docker CLI option : --publish to docker run , equivalent Docker Compose option : ports List of ports to make available to the host machine. Three formats are supported: local:container or local:container/protocol format For example, 1234:5678 or 1234:5678/tcp will make TCP port 5678 inside the container available on the host machine at TCP port 1234, and 1234:5678/udp will make UDP port 5678 inside the container available on the host machine at UDP port 1234. local_from-local_to:container_from:container-to or local_from-local_to:container_from:container-to/protocol format For example, 1000-1001:2025-2026 or 1000-1001:2025-2026/tcp will make TCP port 2025 inside the container available on the host machine at TCP port 1000, and TCP port 2026 inside the container available on the host machine at TCP port 1001. An expanded format: containers : my-container : ... ports : # This is equivalent to 1234:5678 or 1234:5678/tcp - local : 1234 container : 5678 # This is equivalent to 3000:4000/udp - local : 3000 container : 4000 protocol : udp # This is equivalent to 1000-1001:2025-2026 or 1000-1001:2025-2026/tcp - local : 1000-1001 container : 2025-2026 # This is equivalent to 5000-5001:6025-6026/udp - local : 5000-5001 container : 6025-6026 protocol : udp All protocols supported by Docker are supported. The default protocol is TCP if none is provided. The port does not need to have a corresponding EXPOSE instruction in the Dockerfile. For example, the my-container container in the following configuration allows accessing port 5678 from the container on port 1234 on the host machine: container : my-container : ports : - 1234:5678 # or - local : 1234 container : 5678 Tip Exposing ports is only required if you need to access the container from the host machine. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port , even if that port is not listed in ports . For example, if a process running in the http-server container listens on port 2000, any other container in the task can access that at http-server:2000 without port 2000 being listed in ports (or an EXPOSE Dockerfile instruction).","title":"ports"},{"location":"config/Containers.html#privileged","text":"Equivalent Docker CLI option : --privileged to docker run , equivalent Docker Compose option : privileged Set to true to run the container in privileged mode . Defaults to false . See also capabilities_to_add and capabilities_to_drop . For example, the following configuration runs the my-container container in privileged mode: containers : my-container : privileged : true","title":"privileged"},{"location":"config/Containers.html#run_as_current_user","text":"Equivalent Docker CLI option : none, equivalent Docker Compose option : none Run the container with the same UID and GID as the user running batect (rather than the user the Docker daemon runs as, which is root on Linux). This means that any files created by the container will be owned by the user running batect, rather than root. This is really only useful on Linux. On macOS, the Docker daemon runs as the currently logged-in user and so any files created in the container are owned by that user, so this is less of an issue. However, for consistency, the same configuration changes are made on both Linux and macOS. See this page for more information on the effects of this option and why it is necessary. run_as_current_user has the following options:","title":"run_as_current_user"},{"location":"config/Containers.html#enabled","text":"Set to true to enable 'run as current user' mode. Defaults to false .","title":"enabled"},{"location":"config/Containers.html#home_directory","text":"Directory to use as home directory for user inside container. Required if enabled is true , not allowed if enabled is false . This directory is automatically created by batect with the correct owner and group. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten.","title":"home_directory"},{"location":"config/Containers.html#example_2","text":"containers : my-container : image : ruby:2.4.3 run_as_current_user : enabled : true home_directory : /home/container-user","title":"Example"},{"location":"config/Containers.html#setup_commands","text":"Equivalent Docker CLI option : none, equivalent Docker Compose option : none List of commands to run inside the container after it has become healthy but before dependent containers start. See the task lifecycle for more information on the effects of this option. Tip It is recommended that you try to include any setup work in your image's Dockerfile wherever possible (and not use setup commands). Setup commands must be run every time the container starts whereas commands included in your image's Dockerfile only run when the image needs to be built, reducing the time taken for tasks to start. Each setup command has the following options:","title":"setup_commands"},{"location":"config/Containers.html#command_2","text":"The command to run. Required. This command is run in a similar way to the container's command , so the same limitations apply to using shell syntax such as && .","title":"command"},{"location":"config/Containers.html#working_directory","text":"The working directory to use for the command. If no working directory is provided, working_directory is used if it is set, otherwise the image's default working directory is used. If this container is used as the task container and the task overrides the default working directory, that override is ignored when running setup commands. The command will inherit the same environment variables as the container's command (including any specified on the task if this is the task container), runs as the same user and group as the container's command and inherits the same settings for privileged status and capabilities .","title":"working_directory"},{"location":"config/Containers.html#example_3","text":"Let's assume we have the following configuration: containers : database : setup_commands : - command : ./apply-migrations.sh application : dependencies : - database Running the container application will first build or pull the images for both the database and application containers. Once the image for database is ready, database will start and launch the command specified in the Dockerfile, then batect will wait for the container to report as healthy. Once database reports as healthy, it will run ./apply-migrations.sh and wait for it to finish before then starting application .","title":"Example"},{"location":"config/Containers.html#volumes","text":"Equivalent Docker CLI option : --volume to docker run , equivalent Docker Compose option : volumes List of volume mounts to create for the container. Both local mounts (mounting a directory on the host into a container) and cache mounts are supported:","title":"volumes"},{"location":"config/Containers.html#local-mounts","text":"Two formats are supported: local:container or local:container:options format An expanded format: containers : my-container : ... volumes : # This is equivalent to .:/code:cached - local : . container : /code options : cached In both formats, the following fields are supported: local : path to the local file or directory to mount. Can be an expression when using the expanded format. Required. Relative paths will be resolved relative to the current configuration file's directory. On Windows, the local path can use either Windows-style ( path\\to\\thing ) or Unix-style ( path/to/thing ) paths, but for compatibility with users running on other operating systems, using Unix-style paths is recommended. container : path to mount the local file or directory at inside the container. Required. options : standard Docker mount options (such as ro for read-only). Optional. Using options: cached may improve performance when running on macOS and Windows hosts - see this page for further explanation.","title":"Local mounts"},{"location":"config/Containers.html#cache-mounts","text":"Cache mounts provide persistence between task runs without the performance overhead of mounting a directory from the host into the container. They are perfect for directories such as node_modules which contain downloaded dependencies that can safely be reused for each task run. The format for a cache mount is: containers : my-container : ... volumes : - type : cache name : node-modules container : /code/node_modules The following fields are supported: type : must be set to cache . Required. name : name of the cache, must be a valid Docker volume name. The same name can be used to share a cache between multiple containers. Required. container : path to mount the cache directory at inside the container. Required. options : standard Docker mount options (such as ro for read-only). Optional.","title":"Cache mounts"},{"location":"config/Containers.html#working_directory_1","text":"Equivalent Docker CLI option : --workdir to docker run , equivalent Docker Compose option : working_dir Working directory to start the container in. If not provided, the default working directory for the image will be used. Both of these can be overridden for an individual task by specifying a working_directory at the task level . For example, the container my-container in the following configuration will start with the working directory set to /somewhere : containers : my-container : working_directory : /somewhere","title":"working_directory"},{"location":"config/Overview.html","text":"Configuration file overview \u00b6 Note This page reflects the options available in the most recent version of batect. batect uses a YAML-based configuration file. By convention, this file is called batect.yml and is placed in the root of your project (alongside the batect script). You can use a different name or location and tell batect where to find it with the -f option . The following is a sample \"hello world\" configuration file: containers : my-container : image : alpine:3.11.3 tasks : say-hello : description : Say hello to the nice person reading the batect documentation run : container : my-container command : echo 'Hello world!' Run it with ./batect say-hello : $ ./batect say-hello Running say-hello... my-container: running echo 'Hello world!' Hello world! say-hello finished with exit code 0 in 1.2s. Get a list of available tasks with ./batect --list-tasks : $ ./batect --list-tasks Available tasks: - say-hello: Say hello to the nice person reading the batect README Configuration files are made up of: project_name \u00b6 The name of your project. Used to label any images built. If a project name is not provided, the project name is taken from the directory containing the configuration file. For example, if your configuration file is /home/alex/projects/my-cool-app/batect.yml and you do not provide a project name, my-cool-app will be used automatically. Project names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores config_variables \u00b6 Definitions for each of the config variables that are used throughout your configuration, in name: options format. Config variable names must start with a letter and contain only letters, digits, dashes ( - ), periods ( . ) and underscores ( _ ). They must not start with batect . Detailed reference for config_variables containers \u00b6 Definitions for each of the containers that make up your various environments, in name: options format. Container names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores Detailed reference for containers include \u00b6 List of configuration files to include in this project. This is useful for breaking up a large project into smaller files, or for sharing configuration between projects. The format for included files is the same as described on this page. Included files can include further files, but cannot include a project name . Example \u00b6 If /my-project/a.yml contains: containers : my-container : image : alpine:1.2.3 include : - includes/b.yml And /my-project/includes/b.yml contains: tasks : my-task : run : container : my-container Then the resulting configuration is as if /my-project/a.yml was: containers : my-container : image : alpine:1.2.3 tasks : my-task : run : container : my-container Paths in included files \u00b6 Relative paths in included files such as in volume mount paths or build directories will be resolved relative to that file's directory ( /my-project in a.yml and /my-project/includes in b.yml in the example above). Use the built-in batect.project_directory config variable to get the path to the root project directory ( /my-project in the example above), for example: containers : my-other-container : image : alpine:1.2.3 volumes : - local : <{batect.project_directory}/scripts container : /code/scripts tasks \u00b6 Definitions for each of your tasks, the actions you launch through batect, in name: options format. Detailed reference for tasks Expressions \u00b6 Some fields support expressions - references to environment variables on the host or config variables . Expressions are supported in: build_args on containers build_directory on containers environment on containers and tasks the local path in volume mounts on containers Environment variables \u00b6 You can pass environment variables from the host (ie. where you run batect) to the container by using any of the following formats: $name or ${name} : use the value of name from the host as the value inside the container. If name is not set on the host, batect will show an error message and not start the task. ${name:-default} : use the value of name from the host as the value inside the container. If name is not set on the host, default is used instead. default can be empty, so ${name:-} will use the value of name from the host if it is set, or a blank value if it is not set. default is treated as a literal, it cannot be a reference to another variable. For example, to refer to the value of the MY_PASSWORD environment variable on the host, use $MY_PASSWORD or ${MY_PASSWORD} . Or, to default to insecure if MY_PASSWORD is not set, use ${MY_PASSWORD:-insecure} . Config variables \u00b6 You can refer to the value of a config variable with <name or <{name} . Default values for config variables can be specified with default when defining them. Notes \u00b6 When given without braces, name can only contain letters, numbers and underscores. Any other characters are treated as literals (eg. $MY_VAR, 2, 3 with MY_VAR set to 1 results in 1, 2, 3 ). When given with braces, name can contain any character except a closing brace ( } ) or colon ( : ). Combining expressions and literal values is supported (eg. My password is $MY_PASSWORD or <{SERVER}:8080 ). In fields that support expressions, you can escape $ and < with a backslash ( \\ ). Anchors, aliases, extensions and merging \u00b6 batect supports YAML anchors and aliases. This allows you to specify a value in one place, and refer to it elsewhere. For example: somewhere : &value-used-multiple-times the-value # This is equivalent to somewhere-else: the-value somewhere-else : *value-used-multiple-times Anchors ( &... ) must be defined before they are referenced with an alias ( *... ). batect also supports extensions, which behave in an identical way, but allow you to define values before you use it for the first time. The following is equivalent to the example above: .value-used-multiple-times : &value-used-multiple-times the-value somewhere : *value-used-multiple-times somewhere-else : *value-used-multiple-times Extensions must be defined at the root level of your configuration file, and the key must start with a period ( . ). batect also supports the merge operator ( << ) in maps. For example: .common-environment : &common-environment ENABLE_COOL_FEATURE : true DATABASE_HOST : postgres:1234 tasks : run-app : run : ... environment : *common-environment # Just uses the values in common-environment as-is run-app-without-cool-feature : run : ... environment : << : *common-environment # Use common-environment as the basis for the environment in this task... ENABLE_COOL_FEATURE : false # ...but override the value of ENABLE_COOL_FEATURE You can merge a single map with <<: *other-map , or multiple maps with <<: [ *map-1, *map-2 ] . Local values take precedence over values merged into a map (regardless of the position of the << entry), and values from sources earlier in the list of maps take precedence over values from later sources. (For example, if both map-1 and map-2 define a value for PORT in the example earlier, the value in map-1 is used.) Examples \u00b6 Examples are provided in the reference for config_variables , containers and tasks . For further examples and real-world scenarios, take a look at the sample projects .","title":"Overview"},{"location":"config/Overview.html#configuration-file-overview","text":"Note This page reflects the options available in the most recent version of batect. batect uses a YAML-based configuration file. By convention, this file is called batect.yml and is placed in the root of your project (alongside the batect script). You can use a different name or location and tell batect where to find it with the -f option . The following is a sample \"hello world\" configuration file: containers : my-container : image : alpine:3.11.3 tasks : say-hello : description : Say hello to the nice person reading the batect documentation run : container : my-container command : echo 'Hello world!' Run it with ./batect say-hello : $ ./batect say-hello Running say-hello... my-container: running echo 'Hello world!' Hello world! say-hello finished with exit code 0 in 1.2s. Get a list of available tasks with ./batect --list-tasks : $ ./batect --list-tasks Available tasks: - say-hello: Say hello to the nice person reading the batect README Configuration files are made up of:","title":"Configuration file overview"},{"location":"config/Overview.html#project_name","text":"The name of your project. Used to label any images built. If a project name is not provided, the project name is taken from the directory containing the configuration file. For example, if your configuration file is /home/alex/projects/my-cool-app/batect.yml and you do not provide a project name, my-cool-app will be used automatically. Project names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores","title":"project_name"},{"location":"config/Overview.html#config_variables","text":"Definitions for each of the config variables that are used throughout your configuration, in name: options format. Config variable names must start with a letter and contain only letters, digits, dashes ( - ), periods ( . ) and underscores ( _ ). They must not start with batect . Detailed reference for config_variables","title":"config_variables"},{"location":"config/Overview.html#containers","text":"Definitions for each of the containers that make up your various environments, in name: options format. Container names must be valid Docker references: they must contain only: lowercase letters digits dashes ( - ) single consecutive periods ( . ) one or two consecutive underscores ( _ ) they must not start or end with dashes, periods or underscores Detailed reference for containers","title":"containers"},{"location":"config/Overview.html#include","text":"List of configuration files to include in this project. This is useful for breaking up a large project into smaller files, or for sharing configuration between projects. The format for included files is the same as described on this page. Included files can include further files, but cannot include a project name .","title":"include"},{"location":"config/Overview.html#example","text":"If /my-project/a.yml contains: containers : my-container : image : alpine:1.2.3 include : - includes/b.yml And /my-project/includes/b.yml contains: tasks : my-task : run : container : my-container Then the resulting configuration is as if /my-project/a.yml was: containers : my-container : image : alpine:1.2.3 tasks : my-task : run : container : my-container","title":"Example"},{"location":"config/Overview.html#paths-in-included-files","text":"Relative paths in included files such as in volume mount paths or build directories will be resolved relative to that file's directory ( /my-project in a.yml and /my-project/includes in b.yml in the example above). Use the built-in batect.project_directory config variable to get the path to the root project directory ( /my-project in the example above), for example: containers : my-other-container : image : alpine:1.2.3 volumes : - local : <{batect.project_directory}/scripts container : /code/scripts","title":"Paths in included files"},{"location":"config/Overview.html#tasks","text":"Definitions for each of your tasks, the actions you launch through batect, in name: options format. Detailed reference for tasks","title":"tasks"},{"location":"config/Overview.html#expressions","text":"Some fields support expressions - references to environment variables on the host or config variables . Expressions are supported in: build_args on containers build_directory on containers environment on containers and tasks the local path in volume mounts on containers","title":"Expressions"},{"location":"config/Overview.html#environment-variables","text":"You can pass environment variables from the host (ie. where you run batect) to the container by using any of the following formats: $name or ${name} : use the value of name from the host as the value inside the container. If name is not set on the host, batect will show an error message and not start the task. ${name:-default} : use the value of name from the host as the value inside the container. If name is not set on the host, default is used instead. default can be empty, so ${name:-} will use the value of name from the host if it is set, or a blank value if it is not set. default is treated as a literal, it cannot be a reference to another variable. For example, to refer to the value of the MY_PASSWORD environment variable on the host, use $MY_PASSWORD or ${MY_PASSWORD} . Or, to default to insecure if MY_PASSWORD is not set, use ${MY_PASSWORD:-insecure} .","title":"Environment variables"},{"location":"config/Overview.html#config-variables","text":"You can refer to the value of a config variable with <name or <{name} . Default values for config variables can be specified with default when defining them.","title":"Config variables"},{"location":"config/Overview.html#notes","text":"When given without braces, name can only contain letters, numbers and underscores. Any other characters are treated as literals (eg. $MY_VAR, 2, 3 with MY_VAR set to 1 results in 1, 2, 3 ). When given with braces, name can contain any character except a closing brace ( } ) or colon ( : ). Combining expressions and literal values is supported (eg. My password is $MY_PASSWORD or <{SERVER}:8080 ). In fields that support expressions, you can escape $ and < with a backslash ( \\ ).","title":"Notes"},{"location":"config/Overview.html#anchors-aliases-extensions-and-merging","text":"batect supports YAML anchors and aliases. This allows you to specify a value in one place, and refer to it elsewhere. For example: somewhere : &value-used-multiple-times the-value # This is equivalent to somewhere-else: the-value somewhere-else : *value-used-multiple-times Anchors ( &... ) must be defined before they are referenced with an alias ( *... ). batect also supports extensions, which behave in an identical way, but allow you to define values before you use it for the first time. The following is equivalent to the example above: .value-used-multiple-times : &value-used-multiple-times the-value somewhere : *value-used-multiple-times somewhere-else : *value-used-multiple-times Extensions must be defined at the root level of your configuration file, and the key must start with a period ( . ). batect also supports the merge operator ( << ) in maps. For example: .common-environment : &common-environment ENABLE_COOL_FEATURE : true DATABASE_HOST : postgres:1234 tasks : run-app : run : ... environment : *common-environment # Just uses the values in common-environment as-is run-app-without-cool-feature : run : ... environment : << : *common-environment # Use common-environment as the basis for the environment in this task... ENABLE_COOL_FEATURE : false # ...but override the value of ENABLE_COOL_FEATURE You can merge a single map with <<: *other-map , or multiple maps with <<: [ *map-1, *map-2 ] . Local values take precedence over values merged into a map (regardless of the position of the << entry), and values from sources earlier in the list of maps take precedence over values from later sources. (For example, if both map-1 and map-2 define a value for PORT in the example earlier, the value in map-1 is used.)","title":"Anchors, aliases, extensions and merging"},{"location":"config/Overview.html#examples","text":"Examples are provided in the reference for config_variables , containers and tasks . For further examples and real-world scenarios, take a look at the sample projects .","title":"Examples"},{"location":"config/Tasks.html","text":"Task definitions \u00b6 Note This page reflects the options available in the most recent version of batect. Each task definition is made up of the following fields. At least one of run or prerequisites is required. description \u00b6 Description shown when running batect --list-tasks . group \u00b6 Group name used to group tasks when running batect --list-tasks . run \u00b6 Specifies what to do when this task starts. If run is not provided, then prerequisites is required and the tasks listed in prerequisites are run to completion before considering this task complete. run is made up of the following fields: container \u00b6 Container to run for this task. Required. command \u00b6 Command to run for this task. Overrides any command specified on the container definition and the image's default command. If no command is provided here, the command specified on the container definition is used if there is one, otherwise the image's default command is used. Just like when specifying a command for a container, this command is passed to the image's ENTRYPOINT , if there is one. This can prevent shell syntax features like $MY_ENVIRONMENT_VARIABLE and && from working. See the note about entrypoints in the documentation for containers for more information. entrypoint \u00b6 Entrypoint to use to run the command. Overrides any entrypoint specified on the container definition and the image's default entrypoint. If no entrypoint is provided here, the entrypoint specified on the container definition is used if there is one, otherwise the image's default entrypoint is used. Applies to whichever command takes precedence, whether that is the command specified on this task, the command specified on the container , or the image's default command. environment \u00b6 List of environment variables (in name: value format) to pass to the container, in addition to those defined on the container itself. If a variable is specified both here and on the container itself, the value given here will override the value defined on the container. Values can be expressions . ports \u00b6 List of port mappings to create for the container, in addition to those defined on the container itself. Behaves identically to specifying a port mapping directly on the container , and supports the same syntax. working_directory \u00b6 Working directory to use for this task's container. Overrides any working directory on the container definition and the image's default working directory. If no working directory is provided here, the working directory specified on the container definition is used if there is one, otherwise the image's default working directory is used. dependencies \u00b6 List of other containers (not tasks) that should be started and healthy before starting the task container given in run , in addition to those defined on the container itself. The behaviour is the same as if the dependencies were specified for the dependencies property of the task's container's definition. prerequisites \u00b6 List of other tasks that should be run to completion before running this task. If a prerequisite task finishes with a non-zero exit code, then neither this task nor any other prerequisites will be run. The tasks are run in the same order that they are declared in, unless reordering is required to satisfy the prerequisites of this task's prerequisites. Examples \u00b6 For more examples and real-world scenarios, take a look at the sample projects . Minimal configuration \u00b6 tasks : start-app : run : container : app Running the task start-app will start the app container. The container will run the command provided in the container configuration (or the default command in the image if there is no command given for the container definition). Task with prerequisites \u00b6 tasks : build : run : container : build-env command : build.sh start-app : run : container : app prerequisites : - build Running the task start-app will first run the build task (which runs build.sh in the build-env container), and then run the app container. If the command build.sh exits with a non-zero exit code, start-app will not be run. Task with dependencies \u00b6 tasks : start-app : run : container : app dependencies : - database - auth-service-fake Running the task start-app will do the following: Build or pull the images for the app , database and auth-service-fake containers, as appropriate Start the database and auth-service-fake containers Wait for the database and auth-service-fake containers to report themselves as healthy ( if they have health checks defined ) Start the app container Task with environment variables \u00b6 tasks : start-app : run : container : app environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the task start-app will start the app container with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container. Task with port mappings \u00b6 tasks : start-app : run : container : app ports : - 123:456 - local : 1000 container : 2000 Running the task start-app will start the app container with the following port mappings defined: Port 123 on the host will be mapped to port 456 inside the container Port 1000 on the host will be mapped to port 2000 inside the container For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the image used by the app container does not need to contain an EXPOSE instruction for ports 456 or 2000. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the app container, it would access it at app:456 , not app:123 .","title":"Tasks"},{"location":"config/Tasks.html#task-definitions","text":"Note This page reflects the options available in the most recent version of batect. Each task definition is made up of the following fields. At least one of run or prerequisites is required.","title":"Task definitions"},{"location":"config/Tasks.html#description","text":"Description shown when running batect --list-tasks .","title":"description"},{"location":"config/Tasks.html#group","text":"Group name used to group tasks when running batect --list-tasks .","title":"group"},{"location":"config/Tasks.html#run","text":"Specifies what to do when this task starts. If run is not provided, then prerequisites is required and the tasks listed in prerequisites are run to completion before considering this task complete. run is made up of the following fields:","title":"run"},{"location":"config/Tasks.html#container","text":"Container to run for this task. Required.","title":"container"},{"location":"config/Tasks.html#command","text":"Command to run for this task. Overrides any command specified on the container definition and the image's default command. If no command is provided here, the command specified on the container definition is used if there is one, otherwise the image's default command is used. Just like when specifying a command for a container, this command is passed to the image's ENTRYPOINT , if there is one. This can prevent shell syntax features like $MY_ENVIRONMENT_VARIABLE and && from working. See the note about entrypoints in the documentation for containers for more information.","title":"command"},{"location":"config/Tasks.html#entrypoint","text":"Entrypoint to use to run the command. Overrides any entrypoint specified on the container definition and the image's default entrypoint. If no entrypoint is provided here, the entrypoint specified on the container definition is used if there is one, otherwise the image's default entrypoint is used. Applies to whichever command takes precedence, whether that is the command specified on this task, the command specified on the container , or the image's default command.","title":"entrypoint"},{"location":"config/Tasks.html#environment","text":"List of environment variables (in name: value format) to pass to the container, in addition to those defined on the container itself. If a variable is specified both here and on the container itself, the value given here will override the value defined on the container. Values can be expressions .","title":"environment"},{"location":"config/Tasks.html#ports","text":"List of port mappings to create for the container, in addition to those defined on the container itself. Behaves identically to specifying a port mapping directly on the container , and supports the same syntax.","title":"ports"},{"location":"config/Tasks.html#working_directory","text":"Working directory to use for this task's container. Overrides any working directory on the container definition and the image's default working directory. If no working directory is provided here, the working directory specified on the container definition is used if there is one, otherwise the image's default working directory is used.","title":"working_directory"},{"location":"config/Tasks.html#dependencies","text":"List of other containers (not tasks) that should be started and healthy before starting the task container given in run , in addition to those defined on the container itself. The behaviour is the same as if the dependencies were specified for the dependencies property of the task's container's definition.","title":"dependencies"},{"location":"config/Tasks.html#prerequisites","text":"List of other tasks that should be run to completion before running this task. If a prerequisite task finishes with a non-zero exit code, then neither this task nor any other prerequisites will be run. The tasks are run in the same order that they are declared in, unless reordering is required to satisfy the prerequisites of this task's prerequisites.","title":"prerequisites"},{"location":"config/Tasks.html#examples","text":"For more examples and real-world scenarios, take a look at the sample projects .","title":"Examples"},{"location":"config/Tasks.html#minimal-configuration","text":"tasks : start-app : run : container : app Running the task start-app will start the app container. The container will run the command provided in the container configuration (or the default command in the image if there is no command given for the container definition).","title":"Minimal configuration"},{"location":"config/Tasks.html#task-with-prerequisites","text":"tasks : build : run : container : build-env command : build.sh start-app : run : container : app prerequisites : - build Running the task start-app will first run the build task (which runs build.sh in the build-env container), and then run the app container. If the command build.sh exits with a non-zero exit code, start-app will not be run.","title":"Task with prerequisites"},{"location":"config/Tasks.html#task-with-dependencies","text":"tasks : start-app : run : container : app dependencies : - database - auth-service-fake Running the task start-app will do the following: Build or pull the images for the app , database and auth-service-fake containers, as appropriate Start the database and auth-service-fake containers Wait for the database and auth-service-fake containers to report themselves as healthy ( if they have health checks defined ) Start the app container","title":"Task with dependencies"},{"location":"config/Tasks.html#task-with-environment-variables","text":"tasks : start-app : run : container : app environment : COUNTRY : Australia SUPER_SECRET_VALUE : $SECRET_PASSWORD ANOTHER_SECRET_VALUE : ${SECRET_PASSWORD} OPTIMISATION_LEVEL : ${HOST_OPTIMISATION_LEVEL:-none} Running the task start-app will start the app container with the following environment variables: The environment variable COUNTRY will have value Australia . The environment variables SUPER_SECRET_VALUE and ANOTHER_SECRET_VALUE will have the value of the SECRET_PASSWORD environment variable on the host. (So, for example, if SECRET_PASSWORD is abc123 on the host, then SUPER_SECRET_VALUE will have the value abc123 in the container.) If SECRET_PASSWORD is not set on the host, batect will show an error message and not start the task. The environment variable OPTIMISATION_LEVEL will have the value of the HOST_OPTIMISATION_LEVEL environment variable on the host. If HOST_OPTIMISATION_LEVEL is not set on the host, then OPTIMISATION_LEVEL will have the value none in the container.","title":"Task with environment variables"},{"location":"config/Tasks.html#task-with-port-mappings","text":"tasks : start-app : run : container : app ports : - 123:456 - local : 1000 container : 2000 Running the task start-app will start the app container with the following port mappings defined: Port 123 on the host will be mapped to port 456 inside the container Port 1000 on the host will be mapped to port 2000 inside the container For example, this means that if a web server is listening on port 456 within the container, it can be accessed from the host at http://localhost:123 . The Dockerfile for the image used by the app container does not need to contain an EXPOSE instruction for ports 456 or 2000. Note that this does not affect how containers launched by batect as part of the same task access ports used by each other, just how they're exposed to the host. Any container started as part of a task will be able to access any port on any other container at the address container_name:container_port . For example, if a process running in another container wants to access the application running on port 456 in the app container, it would access it at app:456 , not app:123 .","title":"Task with port mappings"},{"location":"tips/BuildArtifactsOwnedByRoot.html","text":"Build artifacts are owned by root \u00b6 tl;dr If a container produces build artifacts in a mounted volume, enable run_as_current_user , otherwise they'll be owned by the root Unix user On Linux, by default, the Docker daemon runs as root, and so all containers run as root. This means that when a container writes a file to a mounted volume, it is owned by the root Unix user, making it difficult for other users to modify or delete the files. This most often comes up when a build task produces an artifact and writes that artifact to a mounted volume. (On macOS and Windows, the Docker daemon runs as the currently logged-in user and so any files created in mounted volumes are owned by that user, so this is not an issue.) To fix this issue, batect can run containers in 'run as current user' mode, ensuring that all files written to a mounted volume are created by the current user, not root. This mode can be enabled on a per-container basis with the run_as_current_user option . When enabled, the following configuration changes are made: The container is run with the current user's UID and GID (equivalent to passing --user $(id -u):$(id -g) to docker run ) An empty directory is mounted into the container at home_directory for the user's home directory. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. A new /etc/passwd file is mounted into the container with two users: root and the current user. The current user's home directory is set to the value of home_directory . (If batect is running as root, then just root is listed and it takes the home directory provided in home_directory .) This means that any other users defined in the container's image are effectively lost. Under most circumstances, this is not an issue. Similarly, a new /etc/group file is mounted into the container with two groups: root and the current user's primary group (usually staff on macOS, and the user's name on Linux). If batect is running as root, then just root is listed. Again, this means that any other groups defined in the container's image are effectively lost. Under most circumstances, this is not an issue. While this is really only useful on Linux, for consistency, batect makes the same configuration changes regardless of the host operating system. These configuration changes are harmless on macOS and Windows. Special notes for Windows \u00b6 On Windows, the container is run with UID 0 and GID 0 and the user and group name root . This is because any mounted directories are always owned by root when running on Windows, and so running as another user can cause issues interacting with mounted directories. For consistency, root's home directory inside the container is set to match the directory specified by home_directory . See docker/for-win#63 and docker/for-win#39 for more details on this limitation.","title":"Build artifacts are owned by root"},{"location":"tips/BuildArtifactsOwnedByRoot.html#build-artifacts-are-owned-by-root","text":"tl;dr If a container produces build artifacts in a mounted volume, enable run_as_current_user , otherwise they'll be owned by the root Unix user On Linux, by default, the Docker daemon runs as root, and so all containers run as root. This means that when a container writes a file to a mounted volume, it is owned by the root Unix user, making it difficult for other users to modify or delete the files. This most often comes up when a build task produces an artifact and writes that artifact to a mounted volume. (On macOS and Windows, the Docker daemon runs as the currently logged-in user and so any files created in mounted volumes are owned by that user, so this is not an issue.) To fix this issue, batect can run containers in 'run as current user' mode, ensuring that all files written to a mounted volume are created by the current user, not root. This mode can be enabled on a per-container basis with the run_as_current_user option . When enabled, the following configuration changes are made: The container is run with the current user's UID and GID (equivalent to passing --user $(id -u):$(id -g) to docker run ) An empty directory is mounted into the container at home_directory for the user's home directory. Warning If the directory given by home_directory already exists inside the image for this container, it is overwritten. A new /etc/passwd file is mounted into the container with two users: root and the current user. The current user's home directory is set to the value of home_directory . (If batect is running as root, then just root is listed and it takes the home directory provided in home_directory .) This means that any other users defined in the container's image are effectively lost. Under most circumstances, this is not an issue. Similarly, a new /etc/group file is mounted into the container with two groups: root and the current user's primary group (usually staff on macOS, and the user's name on Linux). If batect is running as root, then just root is listed. Again, this means that any other groups defined in the container's image are effectively lost. Under most circumstances, this is not an issue. While this is really only useful on Linux, for consistency, batect makes the same configuration changes regardless of the host operating system. These configuration changes are harmless on macOS and Windows.","title":"Build artifacts are owned by root"},{"location":"tips/BuildArtifactsOwnedByRoot.html#special-notes-for-windows","text":"On Windows, the container is run with UID 0 and GID 0 and the user and group name root . This is because any mounted directories are always owned by root when running on Windows, and so running as another user can cause issues interacting with mounted directories. For consistency, root's home directory inside the container is set to match the directory specified by home_directory . See docker/for-win#63 and docker/for-win#39 for more details on this limitation.","title":"Special notes for Windows"},{"location":"tips/IDEIntegration.html","text":"IDE integration \u00b6 Coding assistance \u00b6 tl;dr Some IDEs can't provide their advanced features (eg. code completion) when using batect, but there are solutions Many IDEs rely on having the development environment installed locally in order to provide features like code completion, analysis and tool integration. (For example, a Ruby IDE might need access to a Ruby runtime, and a Java IDE might need the target JVM to be installed.) However, if you're using batect, then all of this is in a container and so the IDE can't access it. Some solutions for this include: Some of the JetBrains family of products natively supports using a SDK or runtime from a container (PyCharm and RubyMine are known to work, although notably IntelliJ does not currently support this). There's more information on how to configure this in the PyCharm docs and RubyMine docs . The Visual Studio Code Remote - Containers extension , currently available with the Insiders build of Visual Studio Code gives the option to use local filesystem and code in a Docker container with your chosen language's runtime and other tools. All the extensions and the IDE features, including full IntelliSense, code navigation and debugging can be used. You could run a text-based editor such as Vim or Emacs in a container (managed by batect, of course) that has your required runtime components installed alongside it. (Have you tried something else that worked? Or do you use another IDE or text editor that supports using runtimes inside a container? Please submit a PR to add to the list above.) Editing batect.yml \u00b6 tl;dr If your editor supports schemastore.org for YAML files, you'll get code completion and other nice features when editing batect.yml batect has a schema published on schemastore.org , which means that if your editor supports schemastore.org for YAML files, you'll get code completion, validation and other nice features automatically. Editors known to support this include: Visual Studio Code with the YAML Support by Red Hat extension JetBrains IDEs (such as IntelliJ, PyCharm and RubyMine) starting with the 2018.2 release","title":"IDE integration"},{"location":"tips/IDEIntegration.html#ide-integration","text":"","title":"IDE integration"},{"location":"tips/IDEIntegration.html#coding-assistance","text":"tl;dr Some IDEs can't provide their advanced features (eg. code completion) when using batect, but there are solutions Many IDEs rely on having the development environment installed locally in order to provide features like code completion, analysis and tool integration. (For example, a Ruby IDE might need access to a Ruby runtime, and a Java IDE might need the target JVM to be installed.) However, if you're using batect, then all of this is in a container and so the IDE can't access it. Some solutions for this include: Some of the JetBrains family of products natively supports using a SDK or runtime from a container (PyCharm and RubyMine are known to work, although notably IntelliJ does not currently support this). There's more information on how to configure this in the PyCharm docs and RubyMine docs . The Visual Studio Code Remote - Containers extension , currently available with the Insiders build of Visual Studio Code gives the option to use local filesystem and code in a Docker container with your chosen language's runtime and other tools. All the extensions and the IDE features, including full IntelliSense, code navigation and debugging can be used. You could run a text-based editor such as Vim or Emacs in a container (managed by batect, of course) that has your required runtime components installed alongside it. (Have you tried something else that worked? Or do you use another IDE or text editor that supports using runtimes inside a container? Please submit a PR to add to the list above.)","title":"Coding assistance"},{"location":"tips/IDEIntegration.html#editing-batectyml","text":"tl;dr If your editor supports schemastore.org for YAML files, you'll get code completion and other nice features when editing batect.yml batect has a schema published on schemastore.org , which means that if your editor supports schemastore.org for YAML files, you'll get code completion, validation and other nice features automatically. Editors known to support this include: Visual Studio Code with the YAML Support by Red Hat extension JetBrains IDEs (such as IntelliJ, PyCharm and RubyMine) starting with the 2018.2 release","title":"Editing batect.yml"},{"location":"tips/Performance.html","text":"Performance \u00b6 I/O performance \u00b6 tl;dr If you're seeing slow build times on macOS or Windows, using batect's caches as well as volume mount options such as cached might help Docker requires features only found in the Linux kernel, and so on macOS and Windows, Docker Desktop runs a lightweight Linux virtual machine to host Docker. However, while this works perfectly fine for most situations, there is some overhead involved in operations that need to work across the host / virtual machine boundary, particularly when it comes to mounting files or directories into a container from the host. While the throughput of mounts on macOS and Windows is generally comparable to native file access within a container, the latency performing I/O operations such as opening a file handle can often be significant, as these need to cross from the Linux VM hosting Docker to the host OS and back again. This increased latency quickly accumulates, especially when many file operations are involved. This particularly affects languages such as JavaScript and Golang that encourage distributing all dependencies as source code and breaking codebases into many small files, as even a warm build with no source code changes still requires the compiler to examine each dependency file to ensure that the cached build result is up-to-date. There are two ways to improve the performance of file I/O when using batect: Use a batect cache backed by a Docker volume wherever possible Otherwise, use the cached mount mode Cache volumes \u00b6 The performance penalty of mounting a file or directory from the host machine does not apply to Docker volumes , as these remain entirely on the Linux VM hosting Docker. This makes them perfect for directories such as caches where persistence between task runs is required, but easy access to their contents is not necessary. batect makes this simple to configure. In your container definition, add a mount to volumes with type: cache . For example, for a typical Node.js application, to cache the node_modules directory in a volume, include the following in your configuration: containers : build-env : image : \"node:13.8.0\" volumes : - local : . container : /code - type : cache name : app-node-modules container : /code/node_modules working_directory : /code batect uses a cache initialisation container to prepare volumes for use as caches. This process ensures that volumes used as caches are readable by containers running with run as current user mode enabled, and that new caches are empty the first time they are used. (Mounting an empty volume into a container copies the contents of the container's directory into the volume, so the cache initialisation process adds an empty .cache-init file to the volume to prevent this behaviour and ensure that the volume is effectively empty.) Tip To make it easier to share caches between builds on ephemeral CI agents, you can instruct batect to use directories instead of volumes, and then use these directories as a starting point for subsequent builds. Run batect with --cache-type=directory to enable this behaviour, then save and restore the .batect/caches directory between builds. Using mounted directories instead of volumes has no performance impact on Linux. Windows containers \u00b6 The performance penalty described above does not apply when mounting directories into Windows containers. batect therefore always uses directory mounts for caches on Windows containers, even if --cache-type=volume is specified on the command line. Mounts in cached mode \u00b6 Info This section only applies to macOS-based hosts, and is only supported by Docker version 17.04 and higher. Enabling cached mode is harmless for other host operating systems. For situations where a cache is not appropriate (eg. mounting your code from the host into a build environment), specifying the cached volume mount option can result in significant performance improvements. (Before you use this option in another context, you should consult the documentation to understand the implications of it.) For example, instead of defining your container like this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code working_directory : /code use this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code options : cached # This enables 'cached' mode for the /code mount working_directory : /code Setting this option will not affect Linux or Windows hosts, so it's safe to commit and share this in a project where some developers use macOS and others use Linux or Windows. Database schema and test data \u00b6 tl;dr Try to do as much work as possible at image build time, rather than doing it every time the container starts A significant amount of time during integration or journey testing with a database can be taken up by preparing the database for use - setting up the schema (usually with some kind of migrations system) and adding the initial test data can take quite some time, especially as the application evolves over time. One way to address this is to bake the schema and test data into the Docker image used for the database, so that this setup cost only has to be paid when building the image or when the setup changes, rather than on every test run. The exact method for doing this will vary depending on the database system you're using, but the general steps that would go in your Dockerfile are: Copy schema and test data scripts into container Temporarily start database daemon Run schema and data scripts against database instance Shut down database daemon Shutdown time \u00b6 tl;dr Make sure signals such as SIGTERM and SIGKILL are being passed to the main process If you notice that post-task cleanup for a container is taking longer than expected, and that container starts the main process from a shell script, make sure that signals such as SIGTERM and SIGKILL are being forwarded to the process. (Otherwise Docker will wait 10 seconds for the application to respond to the signal before just terminating the process.) For example, instead of using: #! /usr/bin/env bash /app/my-really-cool-app --do-stuff use this: #! /usr/bin/env bash exec /app/my-really-cool-app --do-stuff ( source )","title":"Performance"},{"location":"tips/Performance.html#performance","text":"","title":"Performance"},{"location":"tips/Performance.html#io-performance","text":"tl;dr If you're seeing slow build times on macOS or Windows, using batect's caches as well as volume mount options such as cached might help Docker requires features only found in the Linux kernel, and so on macOS and Windows, Docker Desktop runs a lightweight Linux virtual machine to host Docker. However, while this works perfectly fine for most situations, there is some overhead involved in operations that need to work across the host / virtual machine boundary, particularly when it comes to mounting files or directories into a container from the host. While the throughput of mounts on macOS and Windows is generally comparable to native file access within a container, the latency performing I/O operations such as opening a file handle can often be significant, as these need to cross from the Linux VM hosting Docker to the host OS and back again. This increased latency quickly accumulates, especially when many file operations are involved. This particularly affects languages such as JavaScript and Golang that encourage distributing all dependencies as source code and breaking codebases into many small files, as even a warm build with no source code changes still requires the compiler to examine each dependency file to ensure that the cached build result is up-to-date. There are two ways to improve the performance of file I/O when using batect: Use a batect cache backed by a Docker volume wherever possible Otherwise, use the cached mount mode","title":"I/O performance"},{"location":"tips/Performance.html#cache-volumes","text":"The performance penalty of mounting a file or directory from the host machine does not apply to Docker volumes , as these remain entirely on the Linux VM hosting Docker. This makes them perfect for directories such as caches where persistence between task runs is required, but easy access to their contents is not necessary. batect makes this simple to configure. In your container definition, add a mount to volumes with type: cache . For example, for a typical Node.js application, to cache the node_modules directory in a volume, include the following in your configuration: containers : build-env : image : \"node:13.8.0\" volumes : - local : . container : /code - type : cache name : app-node-modules container : /code/node_modules working_directory : /code batect uses a cache initialisation container to prepare volumes for use as caches. This process ensures that volumes used as caches are readable by containers running with run as current user mode enabled, and that new caches are empty the first time they are used. (Mounting an empty volume into a container copies the contents of the container's directory into the volume, so the cache initialisation process adds an empty .cache-init file to the volume to prevent this behaviour and ensure that the volume is effectively empty.) Tip To make it easier to share caches between builds on ephemeral CI agents, you can instruct batect to use directories instead of volumes, and then use these directories as a starting point for subsequent builds. Run batect with --cache-type=directory to enable this behaviour, then save and restore the .batect/caches directory between builds. Using mounted directories instead of volumes has no performance impact on Linux.","title":"Cache volumes"},{"location":"tips/Performance.html#windows-containers","text":"The performance penalty described above does not apply when mounting directories into Windows containers. batect therefore always uses directory mounts for caches on Windows containers, even if --cache-type=volume is specified on the command line.","title":"Windows containers"},{"location":"tips/Performance.html#mounts-in-cached-mode","text":"Info This section only applies to macOS-based hosts, and is only supported by Docker version 17.04 and higher. Enabling cached mode is harmless for other host operating systems. For situations where a cache is not appropriate (eg. mounting your code from the host into a build environment), specifying the cached volume mount option can result in significant performance improvements. (Before you use this option in another context, you should consult the documentation to understand the implications of it.) For example, instead of defining your container like this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code working_directory : /code use this: containers : build-env : image : \"ruby:2.4.3\" volumes : - local : . container : /code options : cached # This enables 'cached' mode for the /code mount working_directory : /code Setting this option will not affect Linux or Windows hosts, so it's safe to commit and share this in a project where some developers use macOS and others use Linux or Windows.","title":"Mounts in cached mode"},{"location":"tips/Performance.html#database-schema-and-test-data","text":"tl;dr Try to do as much work as possible at image build time, rather than doing it every time the container starts A significant amount of time during integration or journey testing with a database can be taken up by preparing the database for use - setting up the schema (usually with some kind of migrations system) and adding the initial test data can take quite some time, especially as the application evolves over time. One way to address this is to bake the schema and test data into the Docker image used for the database, so that this setup cost only has to be paid when building the image or when the setup changes, rather than on every test run. The exact method for doing this will vary depending on the database system you're using, but the general steps that would go in your Dockerfile are: Copy schema and test data scripts into container Temporarily start database daemon Run schema and data scripts against database instance Shut down database daemon","title":"Database schema and test data"},{"location":"tips/Performance.html#shutdown-time","text":"tl;dr Make sure signals such as SIGTERM and SIGKILL are being passed to the main process If you notice that post-task cleanup for a container is taking longer than expected, and that container starts the main process from a shell script, make sure that signals such as SIGTERM and SIGKILL are being forwarded to the process. (Otherwise Docker will wait 10 seconds for the application to respond to the signal before just terminating the process.) For example, instead of using: #! /usr/bin/env bash /app/my-really-cool-app --do-stuff use this: #! /usr/bin/env bash exec /app/my-really-cool-app --do-stuff ( source )","title":"Shutdown time"},{"location":"tips/Proxies.html","text":"Proxies, Docker and batect \u00b6 tl;dr batect will do its best to make things just work with proxies, but you'll need to configure proxies for pulling images yourself Most applications expect to find proxy configuration in a number of environment variables. The most common are: http_proxy : proxy to use for HTTP requests https_proxy : proxy to use for HTTPS requests ftp_proxy : proxy to use for FTP requests no_proxy : comma-separated list of domains or addresses for which connections should bypass the proxy (ie. be direct to the destination) There are three points where a proxy could be required during the lifecycle of a container: at image pull time at build time, after the image has been pulled at run time Each of these are handled slightly differently by Docker, and so batect does its best to make your life easier. At image pull time \u00b6 When pulling an image, the Docker daemon uses any proxy-related environment variables in the Docker daemon's environment to determine whether or not to use a proxy. These settings cannot be set at image pull time, so batect can't configure these settings for you - you must configure them yourself. On macOS, Docker defaults to using your system's proxy settings, and you can change these by going to the Docker icon > Preferences > Proxies. On Linux, you may need to configure the Docker daemon's proxy settings yourself. This page in the Docker documentation gives an example of how to configure a Docker daemon running with systemd. On Windows, you may need to configure the Docker daemon's proxy settings yourself. You can edit Docker's proxy settings by right-clicking the Docker taskbar icon, choosing Settings and then Proxies. At build time, after the image has been pulled \u00b6 After pulling the base image, all subsequent build steps use the environment variables of the build environment, which is a combination of: any environment variables defined in the base image with ENV instructions any build arguments defined in the Dockerfile with ARG instructions any environment variables defined in the Dockerfile with ENV instructions any of the pre-defined build arguments , if a value is provided for them This last point is the most relevant to proxy settings - as http_proxy , https_proxy , no_proxy etc. are defined as pre-defined build arguments, we can pass the host's proxy environment variables into the build environment as build arguments. batect automatically propagates any proxy environment variables configured on the host as build arguments unless the --no-proxy-vars flag is passed to batect . Note that build arguments are not persisted in the image - they exist only as environment variables at build time. Furthermore, the pre-defined proxy-related build arguments (unlike normal build arguments) do not impact Docker's cache invalidation logic - so if an image build succeeded with http_proxy set to http://brokenproxy , changing http_proxy to http://workingproxy will not cause a rebuild. (The reasoning behind this is that if the build has succeeded with one proxy, then switching to another proxy should have no impact.) At run time \u00b6 The set of run time environment variables is defined by: any environment variables defined in the image (including any base images) with ENV instructions any container-specific environment variables specified in the container or task in batect.yml batect automatically propagates any proxy environment variables configured on the host as environment variables unless the --no-proxy-vars flag is passed to batect . Starting with v0.14, if propagating proxy environment variables is enabled, and any proxy environment variable recognised by batect is set, batect will also add the names of all containers started as part of the task to no_proxy and NO_PROXY (or create those environment variables if they're not set). This ensures that inter-container communication is not proxied. Proxy environment variables recognised by batect \u00b6 batect will propagate the following proxy-related environment variables: http_proxy HTTP_PROXY https_proxy HTTPS_PROXY ftp_proxy FTP_PROXY no_proxy NO_PROXY Starting with v0.18, batect will add missing environment variables if only one in a pair is defined. (For example, if http_proxy is defined, but HTTP_PROXY isn't, then both http_proxy and HTTP_PROXY are propagated, with HTTP_PROXY set to the same value as http_proxy .) Proxies running on the host machine \u00b6 If you run a local proxy on your host machine such as Cntlm , referring to this proxy with localhost will not work from inside a Docker container, as localhost refers to the container, not the host machine. If you are running batect on macOS or Windows with Docker 17.06 or later, batect will automatically rewrite proxy-related environment variables that refer to localhost , 127.0.0.1 or ::1 so that they refer to the host machine. If you are running batect on Linux, or using an older version of Docker, batect will not rewrite proxy-related environment variables. Support for Linux will be added in the future, check this issue on GitHub for updates.","title":"Proxies"},{"location":"tips/Proxies.html#proxies-docker-and-batect","text":"tl;dr batect will do its best to make things just work with proxies, but you'll need to configure proxies for pulling images yourself Most applications expect to find proxy configuration in a number of environment variables. The most common are: http_proxy : proxy to use for HTTP requests https_proxy : proxy to use for HTTPS requests ftp_proxy : proxy to use for FTP requests no_proxy : comma-separated list of domains or addresses for which connections should bypass the proxy (ie. be direct to the destination) There are three points where a proxy could be required during the lifecycle of a container: at image pull time at build time, after the image has been pulled at run time Each of these are handled slightly differently by Docker, and so batect does its best to make your life easier.","title":"Proxies, Docker and batect"},{"location":"tips/Proxies.html#at-image-pull-time","text":"When pulling an image, the Docker daemon uses any proxy-related environment variables in the Docker daemon's environment to determine whether or not to use a proxy. These settings cannot be set at image pull time, so batect can't configure these settings for you - you must configure them yourself. On macOS, Docker defaults to using your system's proxy settings, and you can change these by going to the Docker icon > Preferences > Proxies. On Linux, you may need to configure the Docker daemon's proxy settings yourself. This page in the Docker documentation gives an example of how to configure a Docker daemon running with systemd. On Windows, you may need to configure the Docker daemon's proxy settings yourself. You can edit Docker's proxy settings by right-clicking the Docker taskbar icon, choosing Settings and then Proxies.","title":"At image pull time"},{"location":"tips/Proxies.html#at-build-time-after-the-image-has-been-pulled","text":"After pulling the base image, all subsequent build steps use the environment variables of the build environment, which is a combination of: any environment variables defined in the base image with ENV instructions any build arguments defined in the Dockerfile with ARG instructions any environment variables defined in the Dockerfile with ENV instructions any of the pre-defined build arguments , if a value is provided for them This last point is the most relevant to proxy settings - as http_proxy , https_proxy , no_proxy etc. are defined as pre-defined build arguments, we can pass the host's proxy environment variables into the build environment as build arguments. batect automatically propagates any proxy environment variables configured on the host as build arguments unless the --no-proxy-vars flag is passed to batect . Note that build arguments are not persisted in the image - they exist only as environment variables at build time. Furthermore, the pre-defined proxy-related build arguments (unlike normal build arguments) do not impact Docker's cache invalidation logic - so if an image build succeeded with http_proxy set to http://brokenproxy , changing http_proxy to http://workingproxy will not cause a rebuild. (The reasoning behind this is that if the build has succeeded with one proxy, then switching to another proxy should have no impact.)","title":"At build time, after the image has been pulled"},{"location":"tips/Proxies.html#at-run-time","text":"The set of run time environment variables is defined by: any environment variables defined in the image (including any base images) with ENV instructions any container-specific environment variables specified in the container or task in batect.yml batect automatically propagates any proxy environment variables configured on the host as environment variables unless the --no-proxy-vars flag is passed to batect . Starting with v0.14, if propagating proxy environment variables is enabled, and any proxy environment variable recognised by batect is set, batect will also add the names of all containers started as part of the task to no_proxy and NO_PROXY (or create those environment variables if they're not set). This ensures that inter-container communication is not proxied.","title":"At run time"},{"location":"tips/Proxies.html#proxy-environment-variables-recognised-by-batect","text":"batect will propagate the following proxy-related environment variables: http_proxy HTTP_PROXY https_proxy HTTPS_PROXY ftp_proxy FTP_PROXY no_proxy NO_PROXY Starting with v0.18, batect will add missing environment variables if only one in a pair is defined. (For example, if http_proxy is defined, but HTTP_PROXY isn't, then both http_proxy and HTTP_PROXY are propagated, with HTTP_PROXY set to the same value as http_proxy .)","title":"Proxy environment variables recognised by batect"},{"location":"tips/Proxies.html#proxies-running-on-the-host-machine","text":"If you run a local proxy on your host machine such as Cntlm , referring to this proxy with localhost will not work from inside a Docker container, as localhost refers to the container, not the host machine. If you are running batect on macOS or Windows with Docker 17.06 or later, batect will automatically rewrite proxy-related environment variables that refer to localhost , 127.0.0.1 or ::1 so that they refer to the host machine. If you are running batect on Linux, or using an older version of Docker, batect will not rewrite proxy-related environment variables. Support for Linux will be added in the future, check this issue on GitHub for updates.","title":"Proxies running on the host machine"},{"location":"tips/WaitingForDependenciesToBeReady.html","text":"Waiting for dependencies to be ready \u00b6 tl;dr Make sure your image has a health check defined, and batect will take care of the rest When running integration or end-to-end tests, you might need to start a number of external dependencies for your application, such as databases or fakes for external services. However, having these dependencies just running usually isn't sufficient - they also need to be ready to respond to requests. For example, your database of choice might take a few seconds to initialise and start accepting queries, and during this time, any requests to it will fail. So we'd like to avoid starting our tests before we know these things are ready, otherwise they'll fail unnecessarily. batect supports this exact requirement by taking advantage of Docker's health check feature : If a container's image has a health check defined, batect won't start any containers that depend on it until the health check reports that it is healthy. If a container's image does not have a health check defined, it is treated as though it has a health check that immediately reported that it is healthy. If the health check fails to report that the container is healthy before the timeout period expires, batect won't start any other containers and will abort the task. There's a collection of sample health check scripts provided by Docker you can use as inspiration, and the sample projects use this technique extensively.","title":"Waiting for dependencies to be ready"},{"location":"tips/WaitingForDependenciesToBeReady.html#waiting-for-dependencies-to-be-ready","text":"tl;dr Make sure your image has a health check defined, and batect will take care of the rest When running integration or end-to-end tests, you might need to start a number of external dependencies for your application, such as databases or fakes for external services. However, having these dependencies just running usually isn't sufficient - they also need to be ready to respond to requests. For example, your database of choice might take a few seconds to initialise and start accepting queries, and during this time, any requests to it will fail. So we'd like to avoid starting our tests before we know these things are ready, otherwise they'll fail unnecessarily. batect supports this exact requirement by taking advantage of Docker's health check feature : If a container's image has a health check defined, batect won't start any containers that depend on it until the health check reports that it is healthy. If a container's image does not have a health check defined, it is treated as though it has a health check that immediately reported that it is healthy. If the health check fails to report that the container is healthy before the timeout period expires, batect won't start any other containers and will abort the task. There's a collection of sample health check scripts provided by Docker you can use as inspiration, and the sample projects use this technique extensively.","title":"Waiting for dependencies to be ready"},{"location":"tips/Windows.html","text":"Windows \u00b6 Containers can't see contents of mounted directories \u00b6 tl;dr If containers can't see the contents of mounted directories, make sure the credentials Docker is using to access them are up-to-date. Due to an issue in Docker for Windows , if your Windows account credentials change (eg. because your password expires and you change it), Docker does not detect the change and does not show an error message when it later goes to use these credentials to mount directories into containers. The solution is to update the credentials Docker for Windows has stored - right-click on the Docker icon in the notification area, choose Settings, go to Shared Drives and click 'Reset credentials'.","title":"Windows"},{"location":"tips/Windows.html#windows","text":"","title":"Windows"},{"location":"tips/Windows.html#containers-cant-see-contents-of-mounted-directories","text":"tl;dr If containers can't see the contents of mounted directories, make sure the credentials Docker is using to access them are up-to-date. Due to an issue in Docker for Windows , if your Windows account credentials change (eg. because your password expires and you change it), Docker does not detect the change and does not show an error message when it later goes to use these credentials to mount directories into containers. The solution is to update the credentials Docker for Windows has stored - right-click on the Docker icon in the notification area, choose Settings, go to Shared Drives and click 'Reset credentials'.","title":"Containers can't see contents of mounted directories"},{"location":"tools/Buildkite.html","text":"Buildkite \u00b6 Agent requirements \u00b6 batect can be run on any Buildkite agent that meets batect's system requirements - chiefly Docker and a JVM. Running with command evaluation disabled \u00b6 Buildkite supports disabling command evaluation , which requires all build scripts to be invoked without arguments and take any necessary input as environment variables. This prevents the use of the batect wrapper script, as it expects to receive the task name and other options as command line options. There are two solutions to this: Option 1: create step-specific shell scripts that invoke batect \u00b6 In this scenario, you create multiple shell scripts, one for each step in Buildkite. For example, let's say you have three steps in Buildkite: one for building, one for testing, and another for packaging. You would need to create a separate script for each of these steps that invokes batect. Each script would be similar to the following example script that runs a series of different kinds of tests: #! /usr/bin/env bash set -euo pipefail ./batect unitTest ./batect integrationTest ./batect journeyTest Option 2: create a wrapper script that takes the task name as an environment variable \u00b6 In this scenario, you create a single shell script and invoke it with different environment variable values for each step. A basic wrapper script could look something like this: #! /usr/bin/env bash set -euo pipefail ./batect \" $BATECT_TASK \" Configure this in your Buildkite pipeline.yml as follows: steps : - label : Run build command : scripts/batect-wrapper.sh env : BATECT_TASK : build - label : Run unit tests command : scripts/batect-wrapper.sh env : BATECT_TASK : unitTest # ...and so on","title":"Buildkite"},{"location":"tools/Buildkite.html#buildkite","text":"","title":"Buildkite"},{"location":"tools/Buildkite.html#agent-requirements","text":"batect can be run on any Buildkite agent that meets batect's system requirements - chiefly Docker and a JVM.","title":"Agent requirements"},{"location":"tools/Buildkite.html#running-with-command-evaluation-disabled","text":"Buildkite supports disabling command evaluation , which requires all build scripts to be invoked without arguments and take any necessary input as environment variables. This prevents the use of the batect wrapper script, as it expects to receive the task name and other options as command line options. There are two solutions to this:","title":"Running with command evaluation disabled"},{"location":"tools/Buildkite.html#option-1-create-step-specific-shell-scripts-that-invoke-batect","text":"In this scenario, you create multiple shell scripts, one for each step in Buildkite. For example, let's say you have three steps in Buildkite: one for building, one for testing, and another for packaging. You would need to create a separate script for each of these steps that invokes batect. Each script would be similar to the following example script that runs a series of different kinds of tests: #! /usr/bin/env bash set -euo pipefail ./batect unitTest ./batect integrationTest ./batect journeyTest","title":"Option 1: create step-specific shell scripts that invoke batect"},{"location":"tools/Buildkite.html#option-2-create-a-wrapper-script-that-takes-the-task-name-as-an-environment-variable","text":"In this scenario, you create a single shell script and invoke it with different environment variable values for each step. A basic wrapper script could look something like this: #! /usr/bin/env bash set -euo pipefail ./batect \" $BATECT_TASK \" Configure this in your Buildkite pipeline.yml as follows: steps : - label : Run build command : scripts/batect-wrapper.sh env : BATECT_TASK : build - label : Run unit tests command : scripts/batect-wrapper.sh env : BATECT_TASK : unitTest # ...and so on","title":"Option 2: create a wrapper script that takes the task name as an environment variable"},{"location":"tools/CIGeneral.html","text":"General setup for CI systems \u00b6 Requirements \u00b6 batect can be used with any CI system that can execute arbitrary commands. CI agents must meet batect's normal requirements . Long-lived agents \u00b6 tl;dr Set up a Cron job to run docker image prune -f regularly on long-lived CI agents If you are using Dockerfiles to define your containers (as opposed to using a pre-existing image), this can generate a large number of orphaned images (and their associated image layers) over time. While batect goes to great lengths to ensure that containers and networks are cleaned up after every task run, it can't know which images are unused and so it can't safely automatically remove unused images. These orphaned images take up disk space, and, if left unattended, can lead to exhausting all the available disk space. This is especially a problem on CI agents, where a human might not notice this issue until the disk is full. Therefore, it's recommended that CI agents running batect-based builds have a regular task that removes orphaned images. Docker has a built-in command to do this: docker image prune -f (the -f disables the confirmation prompt). The exact frequency will depend on your usage pattern, but once a day is usually more than sufficient.","title":"General"},{"location":"tools/CIGeneral.html#general-setup-for-ci-systems","text":"","title":"General setup for CI systems"},{"location":"tools/CIGeneral.html#requirements","text":"batect can be used with any CI system that can execute arbitrary commands. CI agents must meet batect's normal requirements .","title":"Requirements"},{"location":"tools/CIGeneral.html#long-lived-agents","text":"tl;dr Set up a Cron job to run docker image prune -f regularly on long-lived CI agents If you are using Dockerfiles to define your containers (as opposed to using a pre-existing image), this can generate a large number of orphaned images (and their associated image layers) over time. While batect goes to great lengths to ensure that containers and networks are cleaned up after every task run, it can't know which images are unused and so it can't safely automatically remove unused images. These orphaned images take up disk space, and, if left unattended, can lead to exhausting all the available disk space. This is especially a problem on CI agents, where a human might not notice this issue until the disk is full. Therefore, it's recommended that CI agents running batect-based builds have a regular task that removes orphaned images. Docker has a built-in command to do this: docker image prune -f (the -f disables the confirmation prompt). The exact frequency will depend on your usage pattern, but once a day is usually more than sufficient.","title":"Long-lived agents"},{"location":"tools/CircleCI.html","text":"CircleCI \u00b6 tl;dr Use a machine executor with an image that has a recent version of Docker. CircleCI's recent machine executor images include everything batect requires, so all that needs to be done to use batect with CircleCI is to configure it to use one of those images. A list of available images is published in the CircleCI documentation here . batect requires an image with a compatible version of Docker - currently version 18.03.1 or newer. Adding the following to your .circleci/config.yml file instructs CircleCI to use a machine executor with the 201808-01 image, which contains Docker 18.06: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 steps : - checkout - run : ./batect ... You can see a full example of using batect with CircleCI in the Golang sample project . Caching between builds \u00b6 If you're using caches , you can persist these between builds with the following configuration: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 environment : BATECT_CACHE_TYPE : directory steps : - checkout - restore_cache : key : batect-caches-{{ arch }}-{{ checksum \"path to a file that uniquely identifies the contents of the caches\" }} - # ...other build steps - save_cache : key : batect-caches-{{ arch }}-{{ checksum \"path to a file that uniquely identifies the contents of the caches\" }} paths : - .batect/caches The key should be a value that changes when the contents of the cache change, and remains constant otherwise. A good candidate is the hash of a dependency lockfile, such as Gemfile.lock , package-lock.json , yarn.lock or go.sum . The documentation for caching has more details on key . Simplifying configuration with CircleCI \u00b6 CircleCI supports defining reusable commands within your configuration file. This can be useful if you find yourself running the same series of commands over and over again. For example, if you have a series of jobs, each of which checks out your code, restores the cache, runs a batect task and then saves the cache, you can define a command that contains all of these steps: commands : batect : description : \"Run a task in batect\" parameters : task : type : string steps : - checkout - restore_cache : key : myproject-{{ checksum \"yarn.lock\" }} - run : command : ./batect << parameters.task >> - save_cache : key : myproject-{{ checksum \"yarn.lock\" }} paths : - node_modules/ ...and then reuse it in each job: build : machine : true image : circleci/classic:201808-01 steps : - batect : task : build test : machine : true image : circleci/classic:201808-01 steps : - batect : task : test","title":"CircleCI"},{"location":"tools/CircleCI.html#circleci","text":"tl;dr Use a machine executor with an image that has a recent version of Docker. CircleCI's recent machine executor images include everything batect requires, so all that needs to be done to use batect with CircleCI is to configure it to use one of those images. A list of available images is published in the CircleCI documentation here . batect requires an image with a compatible version of Docker - currently version 18.03.1 or newer. Adding the following to your .circleci/config.yml file instructs CircleCI to use a machine executor with the 201808-01 image, which contains Docker 18.06: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 steps : - checkout - run : ./batect ... You can see a full example of using batect with CircleCI in the Golang sample project .","title":"CircleCI"},{"location":"tools/CircleCI.html#caching-between-builds","text":"If you're using caches , you can persist these between builds with the following configuration: version : 2 jobs : build : machine : enabled : true image : circleci/classic:201808-01 environment : BATECT_CACHE_TYPE : directory steps : - checkout - restore_cache : key : batect-caches-{{ arch }}-{{ checksum \"path to a file that uniquely identifies the contents of the caches\" }} - # ...other build steps - save_cache : key : batect-caches-{{ arch }}-{{ checksum \"path to a file that uniquely identifies the contents of the caches\" }} paths : - .batect/caches The key should be a value that changes when the contents of the cache change, and remains constant otherwise. A good candidate is the hash of a dependency lockfile, such as Gemfile.lock , package-lock.json , yarn.lock or go.sum . The documentation for caching has more details on key .","title":"Caching between builds"},{"location":"tools/CircleCI.html#simplifying-configuration-with-circleci","text":"CircleCI supports defining reusable commands within your configuration file. This can be useful if you find yourself running the same series of commands over and over again. For example, if you have a series of jobs, each of which checks out your code, restores the cache, runs a batect task and then saves the cache, you can define a command that contains all of these steps: commands : batect : description : \"Run a task in batect\" parameters : task : type : string steps : - checkout - restore_cache : key : myproject-{{ checksum \"yarn.lock\" }} - run : command : ./batect << parameters.task >> - save_cache : key : myproject-{{ checksum \"yarn.lock\" }} paths : - node_modules/ ...and then reuse it in each job: build : machine : true image : circleci/classic:201808-01 steps : - batect : task : build test : machine : true image : circleci/classic:201808-01 steps : - batect : task : test","title":"Simplifying configuration with CircleCI"},{"location":"tools/Docker.html","text":"Docker \u00b6 Building and pushing an image \u00b6 You can see an example of building and pushing an image from batect in the Java sample project .","title":"Docker"},{"location":"tools/Docker.html#docker","text":"","title":"Docker"},{"location":"tools/Docker.html#building-and-pushing-an-image","text":"You can see an example of building and pushing an image from batect in the Java sample project .","title":"Building and pushing an image"},{"location":"tools/DotNetCore.html","text":".NET Core \u00b6 Example configuration \u00b6 containers : build-env : image : mcr.microsoft.com/dotnet/core/sdk:3.1.102 volumes : - local : . container : /code options : cached - type : cache name : nuget-cache container : /root/.nuget/packages # Repeat this cache for each project in your codebase: - type : cache name : project1-obj container : /code/project1/obj working_directory : /code Caching dependencies \u00b6 tl;dr Mount a cache into your container for downloaded NuGet packages, otherwise you'll have to download and compile your dependencies every time the build runs By default, dotnet stores downloaded NuGet packages in ~/.nuget/packages . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that dotnet will have to download all of your dependencies again next time you run the task, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into the container at ~/.nuget/packages , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory. Caching build output \u00b6 tl;dr Mount a cache into your container the obj directory for each project in your codebase, otherwise you'll experience poor performance on macOS and Windows, and issues with some IDEs. The obj directory is used to store intermediate build output. However, when running on macOS and Windows, Docker exhibits poor I/O performance for directories mounted from the macOS or Windows host, as discussed in the section on caches . Furthermore, the obj directory contains files that include the absolute path to the NuGet packages in your project, which are only correct in the context of the container. This can cause issues for some IDEs (including Rider) that rely on these files to show code completion information for dependencies. The solution to this is to mount a cache that persists between builds into your container for each project's obj directory.","title":".NET Core"},{"location":"tools/DotNetCore.html#net-core","text":"","title":".NET Core"},{"location":"tools/DotNetCore.html#example-configuration","text":"containers : build-env : image : mcr.microsoft.com/dotnet/core/sdk:3.1.102 volumes : - local : . container : /code options : cached - type : cache name : nuget-cache container : /root/.nuget/packages # Repeat this cache for each project in your codebase: - type : cache name : project1-obj container : /code/project1/obj working_directory : /code","title":"Example configuration"},{"location":"tools/DotNetCore.html#caching-dependencies","text":"tl;dr Mount a cache into your container for downloaded NuGet packages, otherwise you'll have to download and compile your dependencies every time the build runs By default, dotnet stores downloaded NuGet packages in ~/.nuget/packages . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that dotnet will have to download all of your dependencies again next time you run the task, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into the container at ~/.nuget/packages , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory.","title":"Caching dependencies"},{"location":"tools/DotNetCore.html#caching-build-output","text":"tl;dr Mount a cache into your container the obj directory for each project in your codebase, otherwise you'll experience poor performance on macOS and Windows, and issues with some IDEs. The obj directory is used to store intermediate build output. However, when running on macOS and Windows, Docker exhibits poor I/O performance for directories mounted from the macOS or Windows host, as discussed in the section on caches . Furthermore, the obj directory contains files that include the absolute path to the NuGet packages in your project, which are only correct in the context of the container. This can cause issues for some IDEs (including Rider) that rely on these files to show code completion information for dependencies. The solution to this is to mount a cache that persists between builds into your container for each project's obj directory.","title":"Caching build output"},{"location":"tools/GitHubActions.html","text":"GitHub Actions \u00b6 tl;dr Use the ubuntu-18.04 runner. GitHub Actions' Ubuntu 18.04 runners come pre-installed with everything needed to run batect. To use the Ubuntu 18.04 runner, specify runs-on: ubuntu:18.04 in your configuration file. For example: jobs : build : name : \"Build\" runs-on : ubuntu-18.04 steps : - uses : actions/checkout@v1 - name : Build application run : ./batect build Caching between builds \u00b6 If you're using caches , you can persist these between builds with the following configuration: jobs : build : name : \"Build\" runs-on : ubuntu-18.04 env : BATECT_CACHE_TYPE : directory steps : - uses : actions/checkout@v1 - name : Cache dependencies uses : actions/cache@v1 with : path : .batect/caches key : batect-caches-${{ hashFiles('path to a file that uniquely identifies the contents of the caches') }} - # ...other build steps The key should be a value that changes when the contents of the cache change, and remains constant otherwise. A good candidate is the hash of a dependency lockfile, such as Gemfile.lock , package-lock.json , yarn.lock or go.sum . The documentation for caching has more details on key .","title":"GitHub Actions"},{"location":"tools/GitHubActions.html#github-actions","text":"tl;dr Use the ubuntu-18.04 runner. GitHub Actions' Ubuntu 18.04 runners come pre-installed with everything needed to run batect. To use the Ubuntu 18.04 runner, specify runs-on: ubuntu:18.04 in your configuration file. For example: jobs : build : name : \"Build\" runs-on : ubuntu-18.04 steps : - uses : actions/checkout@v1 - name : Build application run : ./batect build","title":"GitHub Actions"},{"location":"tools/GitHubActions.html#caching-between-builds","text":"If you're using caches , you can persist these between builds with the following configuration: jobs : build : name : \"Build\" runs-on : ubuntu-18.04 env : BATECT_CACHE_TYPE : directory steps : - uses : actions/checkout@v1 - name : Cache dependencies uses : actions/cache@v1 with : path : .batect/caches key : batect-caches-${{ hashFiles('path to a file that uniquely identifies the contents of the caches') }} - # ...other build steps The key should be a value that changes when the contents of the cache change, and remains constant otherwise. A good candidate is the hash of a dependency lockfile, such as Gemfile.lock , package-lock.json , yarn.lock or go.sum . The documentation for caching has more details on key .","title":"Caching between builds"},{"location":"tools/Golang.html","text":"Golang \u00b6 You can see a full example of using batect with Golang in the Golang sample project . Example configuration \u00b6 containers : build-env : image : golang:1.14.0-stretch volumes : - local : . container : /code options : cached - type : cache name : go-cache container : /go working_directory : /code environment : # With the image above, GOPATH defaults to /go, so we don't need to set it explicitly. GOCACHE : /go/cache Caching dependencies \u00b6 tl;dr Mount a cache into your container for your GOPATH and GOCACHE , otherwise you'll have to download and compile your dependencies every time the build runs GOPATH \u00b6 Golang caches the source for dependencies under your GOPATH . By default, this is at $HOME/go . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Golang will have to download all of your dependencies again next time you run the task, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into your container for your GOPATH . For example, the official Golang Docker images set GOPATH to /go , so mounting a cache at /go inside the container will allow your dependencies to be persisted across builds. GOCACHE \u00b6 The Golang compiler caches intermediate build output (such as built libraries) in GOCACHE . Just like for GOPATH , the contents of GOCACHE will be lost when the task finishes and the container is removed, which means that Golang will have to recompile all code for your project, even if it has not changed. This can also significantly slow down the build. Again, the solution is to mount a cache that persists between builds into your container for your GOCACHE . The official Golang Docker images do not set a default for GOCACHE , so you will need to set this yourself. In the example above, GOCACHE has been placed inside /go (which is the default GOPATH ) so that both use the same cache.","title":"Golang"},{"location":"tools/Golang.html#golang","text":"You can see a full example of using batect with Golang in the Golang sample project .","title":"Golang"},{"location":"tools/Golang.html#example-configuration","text":"containers : build-env : image : golang:1.14.0-stretch volumes : - local : . container : /code options : cached - type : cache name : go-cache container : /go working_directory : /code environment : # With the image above, GOPATH defaults to /go, so we don't need to set it explicitly. GOCACHE : /go/cache","title":"Example configuration"},{"location":"tools/Golang.html#caching-dependencies","text":"tl;dr Mount a cache into your container for your GOPATH and GOCACHE , otherwise you'll have to download and compile your dependencies every time the build runs","title":"Caching dependencies"},{"location":"tools/Golang.html#gopath","text":"Golang caches the source for dependencies under your GOPATH . By default, this is at $HOME/go . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Golang will have to download all of your dependencies again next time you run the task, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into your container for your GOPATH . For example, the official Golang Docker images set GOPATH to /go , so mounting a cache at /go inside the container will allow your dependencies to be persisted across builds.","title":"GOPATH"},{"location":"tools/Golang.html#gocache","text":"The Golang compiler caches intermediate build output (such as built libraries) in GOCACHE . Just like for GOPATH , the contents of GOCACHE will be lost when the task finishes and the container is removed, which means that Golang will have to recompile all code for your project, even if it has not changed. This can also significantly slow down the build. Again, the solution is to mount a cache that persists between builds into your container for your GOCACHE . The official Golang Docker images do not set a default for GOCACHE , so you will need to set this yourself. In the example above, GOCACHE has been placed inside /go (which is the default GOPATH ) so that both use the same cache.","title":"GOCACHE"},{"location":"tools/Gradle.html","text":"Gradle \u00b6 You can see an example of configuring and using Java and Gradle with batect in the Java sample project . Example configuration \u00b6 containers : build-env : image : openjdk:13.0.2-jdk volumes : - local : . container : /code options : cached - type : cache name : gradle-cache container : /root/.gradle working_directory : /code environment : GRADLE_OPTS : -Dorg.gradle.daemon=false Caching dependencies \u00b6 tl;dr Mount a cache as the ~/.gradle directory within the container, otherwise you'll have to download your dependencies every time the build runs By default, Gradle downloads all of your application's dependencies to the ~/.gradle directory . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Gradle will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into the container at ~/.gradle , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory. Warning With this configuration, you will not be able to run more than one task at a time. This is due to a known issue with Gradle . Disabling the Gradle daemon \u00b6 tl;dr Set the environment variable GRADLE_OPTS to -Dorg.gradle.daemon=false When Gradle starts, it has to load itself and then compile and load your build script so that it can execute it. This can take a noticeable amount of time for larger projects, so, by default, it starts a daemon that remains running and ready to start your build without having to load or compile anything. However, when Gradle is running inside an ephemeral container like the ones created by batect, this daemon is pointless - it will be terminated alongside the rest of the container at the end of the build. In fact, the cost of starting the daemon means that this is actually counter-productive, because we'll pay the performance penalty of starting the daemon every time when we won't then benefit from it in later builds. Therefore, it's best to disable the daemon when running Gradle inside a container. This can be done by setting the GRADLE_OPTS environment variable to -Dorg.gradle.daemon=false .","title":"Gradle"},{"location":"tools/Gradle.html#gradle","text":"You can see an example of configuring and using Java and Gradle with batect in the Java sample project .","title":"Gradle"},{"location":"tools/Gradle.html#example-configuration","text":"containers : build-env : image : openjdk:13.0.2-jdk volumes : - local : . container : /code options : cached - type : cache name : gradle-cache container : /root/.gradle working_directory : /code environment : GRADLE_OPTS : -Dorg.gradle.daemon=false","title":"Example configuration"},{"location":"tools/Gradle.html#caching-dependencies","text":"tl;dr Mount a cache as the ~/.gradle directory within the container, otherwise you'll have to download your dependencies every time the build runs By default, Gradle downloads all of your application's dependencies to the ~/.gradle directory . However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Gradle will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to mount a cache that persists between builds into the container at ~/.gradle , so that these downloaded dependencies are persisted between builds. Note that you can't use ~ in the container path for a volume mount: If you're using run as current user mode , use the home directory you specified for home_directory . If you're not using run as current user mode , use /root as the home directory, as the vast majority of containers default to the root user and use this as the root user's home directory. Warning With this configuration, you will not be able to run more than one task at a time. This is due to a known issue with Gradle .","title":"Caching dependencies"},{"location":"tools/Gradle.html#disabling-the-gradle-daemon","text":"tl;dr Set the environment variable GRADLE_OPTS to -Dorg.gradle.daemon=false When Gradle starts, it has to load itself and then compile and load your build script so that it can execute it. This can take a noticeable amount of time for larger projects, so, by default, it starts a daemon that remains running and ready to start your build without having to load or compile anything. However, when Gradle is running inside an ephemeral container like the ones created by batect, this daemon is pointless - it will be terminated alongside the rest of the container at the end of the build. In fact, the cost of starting the daemon means that this is actually counter-productive, because we'll pay the performance penalty of starting the daemon every time when we won't then benefit from it in later builds. Therefore, it's best to disable the daemon when running Gradle inside a container. This can be done by setting the GRADLE_OPTS environment variable to -Dorg.gradle.daemon=false .","title":"Disabling the Gradle daemon"},{"location":"tools/Node.html","text":"Node.js \u00b6 You can see an example of configuring and using TypeScript and Yarn with batect in the TypeScript sample project , and an example of using Cypress for UI testing with batect in the Cypress sample project . Example configuration \u00b6 containers : build-env : image : node:13.8.0 volumes : - local : . container : /code options : cached - type : cache name : node_modules container : /code/node_modules working_directory : /code enable_init_process : true Caching dependencies \u00b6 tl;dr Mount a cache into your container for the node_modules directory, otherwise you'll experience poor performance on macOS and Windows. Both NPM and Yarn download and store dependencies in the node_modules directory in your application's directory. However, when running on macOS and Windows, Docker exhibits poor I/O performance for directories mounted from the macOS or Windows host, as discussed in the section on caches . The solution to this is to mount a cache that persists between builds into your container for node_modules . Issues with signals not being handled correctly \u00b6 tl;dr If signals such as SIGINT (which is what happens when you press Ctrl+C) aren't being handled correctly by your Node.js-based application, enable enable_init_process for that container Node.js does not behave correctly when it is running as PID 1, which is what happens when running Node.js inside a container. The most noticeable issue this causes is that applications do not respond correctly to signals such as SIGINT (which is generated when you press Ctrl+C). The solution is to run another process (an 'init process') as PID 1, which then runs your application and handles and forwards signals to it. Docker has a slimmed-down init process built in that is designed for just this scenario. You can enable it for a container in batect by setting enable_init_process to true . This article has a more detailed explanation of what is happening and why an init process solves this problem.","title":"Node.js"},{"location":"tools/Node.html#nodejs","text":"You can see an example of configuring and using TypeScript and Yarn with batect in the TypeScript sample project , and an example of using Cypress for UI testing with batect in the Cypress sample project .","title":"Node.js"},{"location":"tools/Node.html#example-configuration","text":"containers : build-env : image : node:13.8.0 volumes : - local : . container : /code options : cached - type : cache name : node_modules container : /code/node_modules working_directory : /code enable_init_process : true","title":"Example configuration"},{"location":"tools/Node.html#caching-dependencies","text":"tl;dr Mount a cache into your container for the node_modules directory, otherwise you'll experience poor performance on macOS and Windows. Both NPM and Yarn download and store dependencies in the node_modules directory in your application's directory. However, when running on macOS and Windows, Docker exhibits poor I/O performance for directories mounted from the macOS or Windows host, as discussed in the section on caches . The solution to this is to mount a cache that persists between builds into your container for node_modules .","title":"Caching dependencies"},{"location":"tools/Node.html#issues-with-signals-not-being-handled-correctly","text":"tl;dr If signals such as SIGINT (which is what happens when you press Ctrl+C) aren't being handled correctly by your Node.js-based application, enable enable_init_process for that container Node.js does not behave correctly when it is running as PID 1, which is what happens when running Node.js inside a container. The most noticeable issue this causes is that applications do not respond correctly to signals such as SIGINT (which is generated when you press Ctrl+C). The solution is to run another process (an 'init process') as PID 1, which then runs your application and handles and forwards signals to it. Docker has a slimmed-down init process built in that is designed for just this scenario. You can enable it for a container in batect by setting enable_init_process to true . This article has a more detailed explanation of what is happening and why an init process solves this problem.","title":"Issues with signals not being handled correctly"},{"location":"tools/Ruby.html","text":"Ruby \u00b6 Bundler \u00b6 You can see an example of configuring and using Ruby and Bundler with batect in the Ruby sample project . Caching dependencies \u00b6 tl;dr Set the BUNDLE_PATH environment variable to a directory within your mounted code directory, otherwise you'll have to download your dependencies every time the build runs By default, Bundler downloads all of your application's dependencies to the ~/.bundle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Bundler will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to set the BUNDLE_PATH environment variable to a directory that persists between builds. If you're already mounting your application's code into the container, then the simplest thing to do is to set BUNDLE_PATH to a directory within that mounted directory. For example, if you're mounting your application's code into the container at /code , set BUNDLE_PATH to /code/.bundle-cache .","title":"Ruby"},{"location":"tools/Ruby.html#ruby","text":"","title":"Ruby"},{"location":"tools/Ruby.html#bundler","text":"You can see an example of configuring and using Ruby and Bundler with batect in the Ruby sample project .","title":"Bundler"},{"location":"tools/Ruby.html#caching-dependencies","text":"tl;dr Set the BUNDLE_PATH environment variable to a directory within your mounted code directory, otherwise you'll have to download your dependencies every time the build runs By default, Bundler downloads all of your application's dependencies to the ~/.bundle directory. However, because batect destroys all of your containers once the task finishes, this directory is lost at the end of every task run - which means that Bundler will have to download all of your dependencies again, significantly slowing down the build. The solution to this is to set the BUNDLE_PATH environment variable to a directory that persists between builds. If you're already mounting your application's code into the container, then the simplest thing to do is to set BUNDLE_PATH to a directory within that mounted directory. For example, if you're mounting your application's code into the container at /code , set BUNDLE_PATH to /code/.bundle-cache .","title":"Caching dependencies"},{"location":"tools/Seq.html","text":"Seq \u00b6 tl;dr Take a look at the Seq sample project for an example of running Seq to capture logs from your application during local development. Seq is a log aggregation and viewing tool that's perfect for browsing logs during local development. You can launch an instance of Seq with the following batect configuration (note that this has a flaw explained below ): containers : sqelf : image : datalust/sqelf:2.0.270 ports : - 12201:12201/udp environment : SEQ_ADDRESS : http://seq:5341 dependencies : - seq seq : image : datalust/seq:5.1.3364 ports : - 9000:80 environment : ACCEPT_EULA : Y This will make the Seq UI available at http://localhost:9000 on your local machine, and allows submitting logs to Seq using the GELF protocol on UDP port 12201. You can combine this with Docker's GELF log driver to automatically send logs to Seq, for example: containers : sqelf : # ... configuration as above seq : # ... configuration as above app : # ... other configuration log_driver : gelf log_options : gelf-address : udp://localhost:12201 dependencies : - sqelf Warning Docker does not support streaming logs to the console when using the GELF log driver. Instead, you'll receive an error message such as Error attaching: configured logging driver does not support reading . This does not affect the operation of your containers, only the ability to see the output in the console. Preventing the loss of logs on startup \u00b6 If you use the configuration above, depending on how quickly your application starts, you may lose some of the first log messages it emits. The solution to this is to specify a healthcheck for the Seq container. For example, you can replace the image with this Dockerfile to add a healthcheck: FROM datalust/seq:5.1.3364 RUN apt-get update && apt-get install -y --no-install-recommends curl HEALTHCHECK --interval = 2s CMD curl \"http://localhost/api\" --fail --show-error --silent And then reference that Dockerfile (saved as .batect/seq/Dockerfile ) in your batect configuration: containers : # ... other containers seq : build_directory : .batect/seq ports : - 9000:80 environment : ACCEPT_EULA : Y","title":"Seq"},{"location":"tools/Seq.html#seq","text":"tl;dr Take a look at the Seq sample project for an example of running Seq to capture logs from your application during local development. Seq is a log aggregation and viewing tool that's perfect for browsing logs during local development. You can launch an instance of Seq with the following batect configuration (note that this has a flaw explained below ): containers : sqelf : image : datalust/sqelf:2.0.270 ports : - 12201:12201/udp environment : SEQ_ADDRESS : http://seq:5341 dependencies : - seq seq : image : datalust/seq:5.1.3364 ports : - 9000:80 environment : ACCEPT_EULA : Y This will make the Seq UI available at http://localhost:9000 on your local machine, and allows submitting logs to Seq using the GELF protocol on UDP port 12201. You can combine this with Docker's GELF log driver to automatically send logs to Seq, for example: containers : sqelf : # ... configuration as above seq : # ... configuration as above app : # ... other configuration log_driver : gelf log_options : gelf-address : udp://localhost:12201 dependencies : - sqelf Warning Docker does not support streaming logs to the console when using the GELF log driver. Instead, you'll receive an error message such as Error attaching: configured logging driver does not support reading . This does not affect the operation of your containers, only the ability to see the output in the console.","title":"Seq"},{"location":"tools/Seq.html#preventing-the-loss-of-logs-on-startup","text":"If you use the configuration above, depending on how quickly your application starts, you may lose some of the first log messages it emits. The solution to this is to specify a healthcheck for the Seq container. For example, you can replace the image with this Dockerfile to add a healthcheck: FROM datalust/seq:5.1.3364 RUN apt-get update && apt-get install -y --no-install-recommends curl HEALTHCHECK --interval = 2s CMD curl \"http://localhost/api\" --fail --show-error --silent And then reference that Dockerfile (saved as .batect/seq/Dockerfile ) in your batect configuration: containers : # ... other containers seq : build_directory : .batect/seq ports : - 9000:80 environment : ACCEPT_EULA : Y","title":"Preventing the loss of logs on startup"},{"location":"tools/TravisCI.html","text":"Travis CI \u00b6 tl;dr Use the Xenial environment, enable Docker and you're all set. Travis CI's Xenial environment includes everything batect requires, so all that needs to be done to use batect with Travis CI is to enable the Docker service. Adding the following to your .travis.yml file selects the Xenial environment and enables Docker: dist : xenial services : - docker You can see a full example of using batect with Travis CI in the Java sample project . Caching between builds \u00b6 If you're using caches , you can persist these between builds with the following configuration: dist : xenial services : - docker env : - BATECT_CACHE_TYPE=directory cache : directories : - .batect/caches","title":"Travis CI"},{"location":"tools/TravisCI.html#travis-ci","text":"tl;dr Use the Xenial environment, enable Docker and you're all set. Travis CI's Xenial environment includes everything batect requires, so all that needs to be done to use batect with Travis CI is to enable the Docker service. Adding the following to your .travis.yml file selects the Xenial environment and enables Docker: dist : xenial services : - docker You can see a full example of using batect with Travis CI in the Java sample project .","title":"Travis CI"},{"location":"tools/TravisCI.html#caching-between-builds","text":"If you're using caches , you can persist these between builds with the following configuration: dist : xenial services : - docker env : - BATECT_CACHE_TYPE=directory cache : directories : - .batect/caches","title":"Caching between builds"}]}